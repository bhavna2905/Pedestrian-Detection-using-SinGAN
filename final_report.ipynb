{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SinGAN on 1 image of the Kitti Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LX5DLAoDiUJp",
    "outputId": "968e5ada-35e0-462c-d9ed-24a0a80bfafa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'SinGAN' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/tamarott/SinGAN.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sRwBbo3RiUVz",
    "outputId": "f37d0890-5dde-446c-9d4b-e5c1214788a4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (1.8.0)\n",
      "Requirement already satisfied: torchvision in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (0.9.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: numpy in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from torch) (1.24.4)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from torchvision) (10.4.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from -r SinGAN/requirements.txt (line 1)) (3.7.5)\n",
      "Requirement already satisfied: scikit-image in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from -r SinGAN/requirements.txt (line 2)) (0.16.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from -r SinGAN/requirements.txt (line 3)) (1.3.2)\n",
      "Requirement already satisfied: scipy in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from -r SinGAN/requirements.txt (line 4)) (1.10.1)\n",
      "Requirement already satisfied: numpy in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from -r SinGAN/requirements.txt (line 5)) (1.24.4)\n",
      "Requirement already satisfied: torch in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from -r SinGAN/requirements.txt (line 6)) (1.8.0)\n",
      "Requirement already satisfied: torchvision in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from -r SinGAN/requirements.txt (line 7)) (0.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->-r SinGAN/requirements.txt (line 1)) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->-r SinGAN/requirements.txt (line 1)) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->-r SinGAN/requirements.txt (line 1)) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->-r SinGAN/requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->-r SinGAN/requirements.txt (line 1)) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->-r SinGAN/requirements.txt (line 1)) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->-r SinGAN/requirements.txt (line 1)) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->-r SinGAN/requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->-r SinGAN/requirements.txt (line 1)) (5.7.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from scikit-image->-r SinGAN/requirements.txt (line 2)) (2.4)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from scikit-image->-r SinGAN/requirements.txt (line 2)) (2.9.0)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from scikit-image->-r SinGAN/requirements.txt (line 2)) (1.1.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->-r SinGAN/requirements.txt (line 3)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->-r SinGAN/requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from torch->-r SinGAN/requirements.txt (line 6)) (4.12.2)\n",
      "Requirement already satisfied: six in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->-r SinGAN/requirements.txt (line 1)) (1.15.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib->-r SinGAN/requirements.txt (line 1)) (3.1.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from networkx>=2.0->scikit-image->-r SinGAN/requirements.txt (line 2)) (4.4.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision\n",
    "\n",
    "!pip install -r SinGAN/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kNYqlIl1u7P2",
    "outputId": "0086fac2-c681-465e-be35-b04fbc8bcff5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bhavnasharma/Downloads/SinGAN\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/bhavnasharma/Downloads/SinGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Exraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_from_file(label_file):\n",
    "    with open(label_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        labels = []\n",
    "        for line in lines:\n",
    "            label = line.strip().split(' ')\n",
    "            labels.append({\n",
    "                \"type\": label[0],\n",
    "                \"left\": float(label[4]),\n",
    "                \"top\": float(label[5]),\n",
    "                \"right\": float(label[6]), \n",
    "                \"bottom\": float(label[7])\n",
    "            })\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop object so it doesnt get distorted during SinGAN and fill space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: 000000_crop.png and 000000_filled.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def crop_and_fill_image(image_path, label_path, output_dir):\n",
    "    original_image = Image.open(image_path)\n",
    "\n",
    "    filled_image = original_image.copy()\n",
    "    draw = ImageDraw.Draw(filled_image)\n",
    "\n",
    "    labels = get_label_from_file(label_path)\n",
    "\n",
    "    for label in labels:\n",
    "        left = int(label[\"left\"])\n",
    "        top = int(label[\"top\"])\n",
    "        right = int(label[\"right\"])\n",
    "        bottom = int(label[\"bottom\"])\n",
    "\n",
    "        cropped_image = original_image.crop((left, top, right, bottom))\n",
    "\n",
    "        draw.rectangle([left, top, right, bottom], fill=(255, 255, 255))\n",
    "\n",
    "    base_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    cropped_filename = f\"{base_filename}_crop.png\"\n",
    "    filled_filename = f\"{base_filename}_filled.png\"\n",
    "\n",
    "    cropped_image.save(os.path.join(output_dir, cropped_filename))\n",
    "\n",
    "    filled_image.save(os.path.join(output_dir, filled_filename))\n",
    "\n",
    "    print(f\"Finished: {cropped_filename} and {filled_filename}\")\n",
    "\n",
    "image_path = '/Users/bhavnasharma/Downloads/data_object_image_2/training/image_2/000000.png'\n",
    "label_path = '/Users/bhavnasharma/Downloads/training/label_2/000000.txt'\n",
    "output_dir = '/Users/bhavnasharma/Downloads/SinGAN/Input/Images'\n",
    "\n",
    "#os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "crop_and_fill_image(image_path, label_path, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create augmentations of Object to give variety of instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img, load_img\n",
    "import numpy as np\n",
    "\n",
    "# Load the cropped pedestrian\n",
    "cropped_pedestrian = load_img('/Users/bhavnasharma/Downloads/SinGAN/Input/Images/000000_crop.png')\n",
    "cropped_pedestrian_array = img_to_array(cropped_pedestrian)\n",
    "\n",
    "# Create an instance of ImageDataGenerator with desired augmentations\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    channel_shift_range=50.0\n",
    ")\n",
    "\n",
    "# Create a directory to save augmented samples if it doesn't exist\n",
    "augmented_samples_dir = '/Users/bhavnasharma/Downloads/SinGAN/aug_images'\n",
    "os.makedirs(augmented_samples_dir, exist_ok=True)\n",
    "\n",
    "# Generate and save 50 augmented samples\n",
    "i = 0\n",
    "for batch in datagen.flow(np.expand_dims(cropped_pedestrian_array, 0), batch_size=1, save_to_dir=augmented_samples_dir, save_prefix='aug', save_format='png'):\n",
    "    i += 1\n",
    "    if i >= 50:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SinGAN and generate 50 backrounds from the 1 input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bwPixYtajyah",
    "outputId": "d3d88393-b164-4992-8b30-50ebec15cd5b"
   },
   "outputs": [],
   "source": [
    "!python main_train.py --input_name 000000_filled.png --not_cuda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above code was used in our previous run and the result model was saved for repeated use. \n",
    "# You can find the saved model in the SinGAN models folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nXVpTIM8jyel",
    "outputId": "0394fb88-b8c8-4bca-fd6b-396e5016a647"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  5358\r\n",
      "random samples for image 000000_filled.png, start scale=0, already exist\r\n"
     ]
    }
   ],
   "source": [
    "!python random_samples.py --input_name 000000_filled.png --mode random_samples --niter 5000 --gen_start_scale 0 --not_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paste the augmented object images over the different backrounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Images 1/50, successful_pastes 3 targets\n",
      "Finished: Images 2/50, successful_pastes 3 targets\n",
      "Finished: Images 3/50, successful_pastes 1 targets\n",
      "Finished: Images 4/50, successful_pastes 5 targets\n",
      "Finished: Images 5/50, successful_pastes 3 targets\n",
      "Finished: Images 6/50, successful_pastes 4 targets\n",
      "Finished: Images 7/50, successful_pastes 5 targets\n",
      "Finished: Images 8/50, successful_pastes 0 targets\n",
      "Finished: Images 9/50, successful_pastes 1 targets\n",
      "Finished: Images 10/50, successful_pastes 1 targets\n",
      "Finished: Images 11/50, successful_pastes 2 targets\n",
      "Finished: Images 12/50, successful_pastes 5 targets\n",
      "Finished: Images 13/50, successful_pastes 2 targets\n",
      "Finished: Images 14/50, successful_pastes 0 targets\n",
      "Finished: Images 15/50, successful_pastes 2 targets\n",
      "Finished: Images 16/50, successful_pastes 3 targets\n",
      "Finished: Images 17/50, successful_pastes 4 targets\n",
      "Finished: Images 18/50, successful_pastes 3 targets\n",
      "Finished: Images 19/50, successful_pastes 2 targets\n",
      "Finished: Images 20/50, successful_pastes 4 targets\n",
      "Finished: Images 21/50, successful_pastes 2 targets\n",
      "Finished: Images 22/50, successful_pastes 3 targets\n",
      "Finished: Images 23/50, successful_pastes 3 targets\n",
      "Finished: Images 24/50, successful_pastes 3 targets\n",
      "Finished: Images 25/50, successful_pastes 3 targets\n",
      "Finished: Images 26/50, successful_pastes 2 targets\n",
      "Finished: Images 27/50, successful_pastes 3 targets\n",
      "Finished: Images 28/50, successful_pastes 2 targets\n",
      "Finished: Images 29/50, successful_pastes 3 targets\n",
      "Finished: Images 30/50, successful_pastes 1 targets\n",
      "Finished: Images 31/50, successful_pastes 1 targets\n",
      "Finished: Images 32/50, successful_pastes 2 targets\n",
      "Finished: Images 33/50, successful_pastes 3 targets\n",
      "Finished: Images 34/50, successful_pastes 3 targets\n",
      "Finished: Images 35/50, successful_pastes 1 targets\n",
      "Finished: Images 36/50, successful_pastes 3 targets\n",
      "Finished: Images 37/50, successful_pastes 1 targets\n",
      "Finished: Images 38/50, successful_pastes 2 targets\n",
      "Finished: Images 39/50, successful_pastes 1 targets\n",
      "Finished: Images 40/50, successful_pastes 3 targets\n",
      "Finished: Images 41/50, successful_pastes 1 targets\n",
      "Finished: Images 42/50, successful_pastes 5 targets\n",
      "Finished: Images 43/50, successful_pastes 2 targets\n",
      "Finished: Images 44/50, successful_pastes 2 targets\n",
      "Finished: Images 45/50, successful_pastes 2 targets\n",
      "Finished: Images 46/50, successful_pastes 2 targets\n",
      "Finished: Images 47/50, successful_pastes 1 targets\n",
      "Finished: Images 48/50, successful_pastes 1 targets\n",
      "Finished: Images 49/50, successful_pastes 4 targets\n",
      "Finished: Images 50/50, successful_pastes 3 targets\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def resize_augmented_image(aug_img, bg_img, max_scale=0.3): \n",
    "    bg_width, bg_height = bg_img.size\n",
    "    aug_width, aug_height = aug_img.size\n",
    "\n",
    "    # random shrink image\n",
    "    scale = random.uniform(0.05, max_scale)\n",
    "\n",
    "    new_width = int(bg_width * scale)\n",
    "    new_width = max(1, new_width)\n",
    "    new_height = int(aug_height * new_width / aug_width)\n",
    "    new_height = max(1, new_height)\n",
    "\n",
    "    return aug_img.resize((new_width, new_height), Image.LANCZOS)\n",
    "\n",
    "def check_overlap(new_box, existing_boxes, margin=10):\n",
    "    x1, y1, x2, y2 = new_box\n",
    "    for box in existing_boxes:\n",
    "        ex1, ey1, ex2, ey2 = box\n",
    "        # add margin check\n",
    "        if not (x2 + margin < ex1 or x1 - margin > ex2 or\n",
    "                y2 + margin < ey1 or y1 - margin > ey2):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def find_non_overlapping_position(bg_size, aug_size, existing_boxes, max_attempts=50):\n",
    "    \"\"\"find non overlap positions\"\"\"\n",
    "    bg_width, bg_height = bg_size\n",
    "    aug_width, aug_height = aug_size\n",
    "\n",
    "    if aug_width >= bg_width or aug_height >= bg_height:\n",
    "        return None\n",
    "\n",
    "    # effective random region (not outside background)\n",
    "    max_x = max(0, bg_width - aug_width)\n",
    "    max_y = max(0, bg_height - aug_height)\n",
    "\n",
    "    if max_x == 0 or max_y == 0:\n",
    "        return None\n",
    "\n",
    "    for _ in range(max_attempts):\n",
    "        x = random.randint(0, max_x)\n",
    "        y = random.randint(0, max_y)\n",
    "        new_box = (x, y, x + aug_width, y + aug_height)\n",
    "\n",
    "        if not check_overlap(new_box, existing_boxes):\n",
    "            return x, y\n",
    "\n",
    "    return None  \n",
    "\n",
    "def create_label(image_width, image_height, obj_coords, obj_size):\n",
    "    \"\"\"Create YOLO format label\"\"\"\n",
    "    x, y = obj_coords\n",
    "    width, height = obj_size\n",
    "\n",
    "    x_center = (x + width/2) / image_width\n",
    "    y_center = (y + height/2) / image_height\n",
    "    norm_width = width / image_width\n",
    "    norm_height = height / image_height\n",
    "\n",
    "    x_center = max(0, min(1, x_center))\n",
    "    y_center = max(0, min(1, y_center))\n",
    "    norm_width = max(0, min(1, norm_width))\n",
    "    norm_height = max(0, min(1, norm_height))\n",
    "\n",
    "    return f\"0 {x_center:.6f} {y_center:.6f} {norm_width:.6f} {norm_height:.6f}\"\n",
    "\n",
    "def paste_images_and_create_labels(bg_dir, aug_dir, output_dir, label_dir):\n",
    "    \"\"\"Paste image to background\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    os.makedirs(label_dir, exist_ok=True)\n",
    "\n",
    "    bg_images = [f for f in os.listdir(bg_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    aug_images = [f for f in os.listdir(aug_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    for i, bg_image_name in enumerate(bg_images):\n",
    "        bg_image = Image.open(os.path.join(bg_dir, bg_image_name))\n",
    "        bg_width, bg_height = bg_image.size\n",
    "\n",
    "        num_images = random.randint(1, 5)\n",
    "        existing_boxes = []\n",
    "        labels = []\n",
    "\n",
    "        successful_pastes = 0\n",
    "        max_attempts = num_images * 2 \n",
    "        attempts = 0\n",
    "\n",
    "        while successful_pastes < num_images and attempts < max_attempts:\n",
    "            aug_image_name = random.choice(aug_images)\n",
    "            aug_image = Image.open(os.path.join(aug_dir, aug_image_name))\n",
    "            aug_image = resize_augmented_image(aug_image, bg_image)\n",
    "            aug_width, aug_height = aug_image.size\n",
    "\n",
    "            # find non overlap position\n",
    "            position = find_non_overlapping_position(\n",
    "                (bg_width, bg_height),\n",
    "                (aug_width, aug_height),\n",
    "                existing_boxes\n",
    "            )\n",
    "\n",
    "            if position is not None:\n",
    "                x, y = position\n",
    "                bg_image.paste(aug_image, (x, y), aug_image if aug_image.mode == 'RGBA' else None)\n",
    "\n",
    "                # label area\n",
    "                existing_boxes.append((x, y, x + aug_width, y + aug_height))\n",
    "\n",
    "                # create label\n",
    "                label = create_label(bg_width, bg_height, (x, y), (aug_width, aug_height))\n",
    "                labels.append(label)\n",
    "\n",
    "                successful_pastes += 1\n",
    "\n",
    "            attempts += 1\n",
    "\n",
    "        # Save\n",
    "        bg_image.save(os.path.join(output_dir, f\"{i:06d}.png\"))\n",
    "        with open(os.path.join(label_dir, f\"{i:06d}.txt\"), 'w') as f:\n",
    "            for label in labels:\n",
    "                f.write(label + '\\n')\n",
    "\n",
    "        print(f\"Finished: Images {i+1}/{len(bg_images)}, successful_pastes {successful_pastes} targets\")\n",
    "\n",
    "# set path\n",
    "bg_dir = \"/Users/bhavnasharma/Downloads/SinGAN/Output/RandomSamples/000000_filled/gen_start_scale=0\"\n",
    "aug_dir = \"/Users/bhavnasharma/Downloads/SinGAN/aug_images\"\n",
    "output_dir = \"/Users/bhavnasharma/Downloads/SinGAN/Results/images\"\n",
    "label_dir = \"/Users/bhavnasharma/Downloads/SinGAN/Results/labels\"\n",
    "\n",
    "# process\n",
    "paste_images_and_create_labels(bg_dir, aug_dir, output_dir, label_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SinGAN to increase the resolution of the produced images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "Random Seed:  9301\n",
      "*** Train SinGAN for SR ***\n",
      "GeneratorConcatSkip2CleanAdd(\n",
      "  (head): ConvBlock(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (body): Sequential(\n",
      "    (block1): ConvBlock(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (block2): ConvBlock(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (block3): ConvBlock(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (tail): Sequential(\n",
      "    (0): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): Tanh()\n",
      "  )\n",
      ")\n",
      "WDiscriminator(\n",
      "  (head): ConvBlock(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (body): Sequential(\n",
      "    (block1): ConvBlock(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (block2): ConvBlock(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (block3): ConvBlock(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (tail): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1))\n",
      ")\n",
      "scale 0:[0/2000]\n",
      "scale 0:[25/2000]\n",
      "scale 0:[50/2000]\n",
      "scale 0:[75/2000]\n",
      "scale 0:[100/2000]\n",
      "scale 0:[125/2000]\n",
      "scale 0:[150/2000]\n",
      "scale 0:[175/2000]\n",
      "scale 0:[200/2000]\n",
      "scale 0:[225/2000]\n",
      "scale 0:[250/2000]\n",
      "scale 0:[275/2000]\n",
      "scale 0:[300/2000]\n",
      "scale 0:[325/2000]\n",
      "scale 0:[350/2000]\n",
      "scale 0:[375/2000]\n",
      "scale 0:[400/2000]\n",
      "scale 0:[425/2000]\n",
      "scale 0:[450/2000]\n",
      "scale 0:[475/2000]\n",
      "scale 0:[500/2000]\n",
      "scale 0:[525/2000]\n",
      "scale 0:[550/2000]\n",
      "scale 0:[575/2000]\n",
      "scale 0:[600/2000]\n",
      "scale 0:[625/2000]\n",
      "scale 0:[650/2000]\n",
      "scale 0:[675/2000]\n",
      "scale 0:[700/2000]\n",
      "scale 0:[725/2000]\n",
      "scale 0:[750/2000]\n",
      "scale 0:[775/2000]\n",
      "scale 0:[800/2000]\n",
      "scale 0:[825/2000]\n",
      "scale 0:[850/2000]\n",
      "scale 0:[875/2000]\n",
      "scale 0:[900/2000]\n",
      "scale 0:[925/2000]\n",
      "scale 0:[950/2000]\n",
      "scale 0:[975/2000]\n",
      "scale 0:[1000/2000]\n",
      "scale 0:[1025/2000]\n",
      "scale 0:[1050/2000]\n",
      "scale 0:[1075/2000]\n",
      "scale 0:[1100/2000]\n",
      "scale 0:[1125/2000]\n",
      "scale 0:[1150/2000]\n",
      "scale 0:[1175/2000]\n",
      "scale 0:[1200/2000]\n",
      "scale 0:[1225/2000]\n",
      "scale 0:[1250/2000]\n",
      "scale 0:[1275/2000]\n",
      "scale 0:[1300/2000]\n",
      "scale 0:[1325/2000]\n",
      "scale 0:[1350/2000]\n",
      "scale 0:[1375/2000]\n",
      "scale 0:[1400/2000]\n",
      "scale 0:[1425/2000]\n",
      "scale 0:[1450/2000]\n",
      "scale 0:[1475/2000]\n",
      "scale 0:[1500/2000]\n",
      "scale 0:[1525/2000]\n",
      "scale 0:[1550/2000]\n",
      "scale 0:[1575/2000]\n",
      "scale 0:[1600/2000]\n",
      "scale 0:[1625/2000]\n",
      "scale 0:[1650/2000]\n",
      "scale 0:[1675/2000]\n",
      "scale 0:[1700/2000]\n",
      "scale 0:[1725/2000]\n",
      "scale 0:[1750/2000]\n",
      "scale 0:[1775/2000]\n",
      "scale 0:[1800/2000]\n",
      "scale 0:[1825/2000]\n",
      "scale 0:[1850/2000]\n",
      "scale 0:[1875/2000]\n",
      "scale 0:[1900/2000]\n",
      "scale 0:[1925/2000]\n",
      "scale 0:[1950/2000]\n",
      "scale 0:[1975/2000]\n",
      "scale 0:[1999/2000]\n",
      "GeneratorConcatSkip2CleanAdd(\n",
      "  (head): ConvBlock(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (body): Sequential(\n",
      "    (block1): ConvBlock(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (block2): ConvBlock(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (block3): ConvBlock(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (tail): Sequential(\n",
      "    (0): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): Tanh()\n",
      "  )\n",
      ")\n",
      "WDiscriminator(\n",
      "  (head): ConvBlock(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (body): Sequential(\n",
      "    (block1): ConvBlock(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (block2): ConvBlock(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (block3): ConvBlock(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (tail): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1))\n",
      ")\n",
      "scale 1:[0/2000]\n",
      "scale 1:[25/2000]\n",
      "scale 1:[50/2000]\n",
      "scale 1:[75/2000]\n",
      "scale 1:[100/2000]\n",
      "scale 1:[125/2000]\n",
      "scale 1:[150/2000]\n",
      "scale 1:[175/2000]\n",
      "scale 1:[200/2000]\n",
      "scale 1:[225/2000]\n",
      "scale 1:[250/2000]\n",
      "scale 1:[275/2000]\n",
      "scale 1:[300/2000]\n",
      "scale 1:[325/2000]\n",
      "scale 1:[350/2000]\n",
      "scale 1:[375/2000]\n",
      "scale 1:[400/2000]\n",
      "scale 1:[425/2000]\n",
      "scale 1:[450/2000]\n",
      "scale 1:[475/2000]\n",
      "scale 1:[500/2000]\n",
      "scale 1:[525/2000]\n",
      "scale 1:[550/2000]\n",
      "scale 1:[575/2000]\n",
      "scale 1:[600/2000]\n",
      "scale 1:[625/2000]\n",
      "scale 1:[650/2000]\n",
      "scale 1:[675/2000]\n",
      "scale 1:[700/2000]\n",
      "scale 1:[725/2000]\n",
      "scale 1:[750/2000]\n",
      "scale 1:[775/2000]\n",
      "scale 1:[800/2000]\n",
      "scale 1:[825/2000]\n",
      "scale 1:[850/2000]\n",
      "scale 1:[875/2000]\n",
      "scale 1:[900/2000]\n",
      "scale 1:[925/2000]\n",
      "scale 1:[950/2000]\n",
      "scale 1:[975/2000]\n",
      "scale 1:[1000/2000]\n",
      "scale 1:[1025/2000]\n",
      "scale 1:[1050/2000]\n",
      "scale 1:[1075/2000]\n",
      "scale 1:[1100/2000]\n",
      "scale 1:[1125/2000]\n",
      "scale 1:[1150/2000]\n",
      "scale 1:[1175/2000]\n",
      "scale 1:[1200/2000]\n",
      "scale 1:[1225/2000]\n",
      "scale 1:[1250/2000]\n",
      "scale 1:[1275/2000]\n",
      "scale 1:[1300/2000]\n",
      "scale 1:[1325/2000]\n",
      "scale 1:[1350/2000]\n",
      "scale 1:[1375/2000]\n",
      "scale 1:[1400/2000]\n",
      "scale 1:[1425/2000]\n",
      "scale 1:[1450/2000]\n",
      "scale 1:[1475/2000]\n",
      "scale 1:[1500/2000]\n",
      "scale 1:[1525/2000]\n",
      "scale 1:[1550/2000]\n",
      "scale 1:[1575/2000]\n",
      "scale 1:[1600/2000]\n",
      "scale 1:[1625/2000]\n",
      "scale 1:[1650/2000]\n",
      "scale 1:[1675/2000]\n",
      "scale 1:[1700/2000]\n",
      "scale 1:[1725/2000]\n",
      "scale 1:[1750/2000]\n",
      "scale 1:[1775/2000]\n",
      "scale 1:[1800/2000]\n",
      "scale 1:[1825/2000]\n",
      "scale 1:[1850/2000]\n",
      "scale 1:[1875/2000]\n",
      "scale 1:[1900/2000]\n",
      "scale 1:[1925/2000]\n",
      "scale 1:[1950/2000]\n",
      "scale 1:[1975/2000]\n",
      "scale 1:[1999/2000]\n",
      "GeneratorConcatSkip2CleanAdd(\n",
      "  (head): ConvBlock(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (body): Sequential(\n",
      "    (block1): ConvBlock(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (block2): ConvBlock(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (block3): ConvBlock(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (tail): Sequential(\n",
      "    (0): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): Tanh()\n",
      "  )\n",
      ")\n",
      "WDiscriminator(\n",
      "  (head): ConvBlock(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (body): Sequential(\n",
      "    (block1): ConvBlock(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (block2): ConvBlock(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (block3): ConvBlock(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (tail): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1))\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale 2:[0/2000]\n",
      "scale 2:[25/2000]\n",
      "scale 2:[50/2000]\n",
      "scale 2:[75/2000]\n",
      "scale 2:[100/2000]\n",
      "scale 2:[125/2000]\n",
      "scale 2:[150/2000]\n",
      "scale 2:[175/2000]\n",
      "scale 2:[200/2000]\n",
      "scale 2:[225/2000]\n",
      "scale 2:[250/2000]\n",
      "scale 2:[275/2000]\n",
      "scale 2:[300/2000]\n",
      "scale 2:[325/2000]\n",
      "scale 2:[350/2000]\n",
      "scale 2:[375/2000]\n",
      "scale 2:[400/2000]\n",
      "scale 2:[425/2000]\n",
      "scale 2:[450/2000]\n",
      "scale 2:[475/2000]\n",
      "scale 2:[500/2000]\n",
      "scale 2:[525/2000]\n",
      "scale 2:[550/2000]\n",
      "scale 2:[575/2000]\n",
      "scale 2:[600/2000]\n",
      "scale 2:[625/2000]\n",
      "scale 2:[650/2000]\n",
      "scale 2:[675/2000]\n",
      "scale 2:[700/2000]\n",
      "scale 2:[725/2000]\n",
      "scale 2:[750/2000]\n",
      "scale 2:[775/2000]\n",
      "scale 2:[800/2000]\n",
      "scale 2:[825/2000]\n",
      "scale 2:[850/2000]\n",
      "scale 2:[875/2000]\n",
      "scale 2:[900/2000]\n",
      "scale 2:[925/2000]\n",
      "scale 2:[950/2000]\n",
      "scale 2:[975/2000]\n",
      "scale 2:[1000/2000]\n",
      "scale 2:[1025/2000]\n",
      "scale 2:[1050/2000]\n",
      "scale 2:[1075/2000]\n",
      "scale 2:[1100/2000]\n",
      "scale 2:[1125/2000]\n",
      "scale 2:[1150/2000]\n",
      "scale 2:[1175/2000]\n",
      "scale 2:[1200/2000]\n",
      "scale 2:[1225/2000]\n",
      "scale 2:[1250/2000]\n",
      "scale 2:[1275/2000]\n",
      "scale 2:[1300/2000]\n",
      "scale 2:[1325/2000]\n",
      "scale 2:[1350/2000]\n",
      "scale 2:[1375/2000]\n",
      "scale 2:[1400/2000]\n",
      "scale 2:[1425/2000]\n",
      "scale 2:[1450/2000]\n",
      "scale 2:[1475/2000]\n",
      "scale 2:[1500/2000]\n",
      "scale 2:[1525/2000]\n",
      "scale 2:[1550/2000]\n",
      "scale 2:[1575/2000]\n",
      "scale 2:[1600/2000]\n",
      "scale 2:[1625/2000]\n",
      "scale 2:[1650/2000]\n",
      "scale 2:[1675/2000]\n",
      "scale 2:[1700/2000]\n",
      "scale 2:[1725/2000]\n",
      "scale 2:[1750/2000]\n",
      "scale 2:[1775/2000]\n",
      "scale 2:[1800/2000]\n",
      "scale 2:[1825/2000]\n",
      "scale 2:[1850/2000]\n",
      "scale 2:[1875/2000]\n",
      "scale 2:[1900/2000]\n",
      "scale 2:[1925/2000]\n",
      "scale 2:[1950/2000]\n",
      "scale 2:[1975/2000]\n",
      "scale 2:[1999/2000]\n",
      "GeneratorConcatSkip2CleanAdd(\n",
      "  (head): ConvBlock(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (body): Sequential(\n",
      "    (block1): ConvBlock(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (block2): ConvBlock(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (block3): ConvBlock(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (tail): Sequential(\n",
      "    (0): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): Tanh()\n",
      "  )\n",
      ")\n",
      "WDiscriminator(\n",
      "  (head): ConvBlock(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (body): Sequential(\n",
      "    (block1): ConvBlock(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (block2): ConvBlock(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (block3): ConvBlock(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (tail): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1))\n",
      ")\n",
      "scale 3:[0/2000]\n",
      "scale 3:[25/2000]\n",
      "scale 3:[50/2000]\n",
      "scale 3:[75/2000]\n",
      "scale 3:[100/2000]\n",
      "scale 3:[125/2000]\n",
      "scale 3:[150/2000]\n",
      "scale 3:[175/2000]\n",
      "scale 3:[200/2000]\n",
      "scale 3:[225/2000]\n",
      "scale 3:[250/2000]\n",
      "scale 3:[275/2000]\n",
      "scale 3:[300/2000]\n",
      "scale 3:[325/2000]\n",
      "scale 3:[350/2000]\n",
      "scale 3:[375/2000]\n",
      "scale 3:[400/2000]\n",
      "scale 3:[425/2000]\n",
      "scale 3:[450/2000]\n",
      "scale 3:[475/2000]\n",
      "scale 3:[500/2000]\n",
      "scale 3:[525/2000]\n",
      "scale 3:[550/2000]\n",
      "scale 3:[575/2000]\n",
      "scale 3:[600/2000]\n",
      "scale 3:[625/2000]\n",
      "scale 3:[650/2000]\n",
      "scale 3:[675/2000]\n",
      "scale 3:[700/2000]\n",
      "scale 3:[725/2000]\n",
      "scale 3:[750/2000]\n",
      "scale 3:[775/2000]\n",
      "scale 3:[800/2000]\n",
      "scale 3:[825/2000]\n",
      "scale 3:[850/2000]\n",
      "scale 3:[875/2000]\n",
      "scale 3:[900/2000]\n",
      "scale 3:[925/2000]\n",
      "scale 3:[950/2000]\n",
      "scale 3:[975/2000]\n",
      "scale 3:[1000/2000]\n",
      "scale 3:[1025/2000]\n",
      "scale 3:[1050/2000]\n",
      "scale 3:[1075/2000]\n",
      "scale 3:[1100/2000]\n",
      "scale 3:[1125/2000]\n",
      "scale 3:[1150/2000]\n",
      "scale 3:[1175/2000]\n",
      "scale 3:[1200/2000]\n",
      "scale 3:[1225/2000]\n",
      "scale 3:[1250/2000]\n",
      "scale 3:[1275/2000]\n",
      "scale 3:[1300/2000]\n",
      "scale 3:[1325/2000]\n",
      "scale 3:[1350/2000]\n",
      "scale 3:[1375/2000]\n",
      "scale 3:[1400/2000]\n",
      "scale 3:[1425/2000]\n",
      "scale 3:[1450/2000]\n",
      "scale 3:[1475/2000]\n",
      "scale 3:[1500/2000]\n",
      "scale 3:[1525/2000]\n",
      "scale 3:[1550/2000]\n",
      "scale 3:[1575/2000]\n",
      "scale 3:[1600/2000]\n",
      "scale 3:[1625/2000]\n",
      "scale 3:[1650/2000]\n",
      "scale 3:[1675/2000]\n",
      "scale 3:[1700/2000]\n",
      "scale 3:[1725/2000]\n",
      "scale 3:[1750/2000]\n",
      "scale 3:[1775/2000]\n",
      "scale 3:[1800/2000]\n",
      "scale 3:[1825/2000]\n",
      "scale 3:[1850/2000]\n",
      "scale 3:[1875/2000]\n",
      "scale 3:[1900/2000]\n",
      "scale 3:[1925/2000]\n",
      "scale 3:[1950/2000]\n",
      "scale 3:[1975/2000]\n",
      "scale 3:[1999/2000]\n",
      "GeneratorConcatSkip2CleanAdd(\n",
      "  (head): ConvBlock(\n",
      "    (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (body): Sequential(\n",
      "    (block1): ConvBlock(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (block2): ConvBlock(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (block3): ConvBlock(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (tail): Sequential(\n",
      "    (0): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): Tanh()\n",
      "  )\n",
      ")\n",
      "WDiscriminator(\n",
      "  (head): ConvBlock(\n",
      "    (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (body): Sequential(\n",
      "    (block1): ConvBlock(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (block2): ConvBlock(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (block3): ConvBlock(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (tail): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1))\n",
      ")\n",
      "scale 4:[0/2000]\n",
      "scale 4:[25/2000]\n",
      "scale 4:[50/2000]\n",
      "scale 4:[75/2000]\n",
      "scale 4:[100/2000]\n",
      "scale 4:[125/2000]\n",
      "scale 4:[150/2000]\n",
      "scale 4:[175/2000]\n",
      "scale 4:[200/2000]\n",
      "scale 4:[225/2000]\n",
      "scale 4:[250/2000]\n",
      "scale 4:[275/2000]\n",
      "scale 4:[300/2000]\n",
      "scale 4:[325/2000]\n",
      "scale 4:[350/2000]\n",
      "scale 4:[375/2000]\n",
      "scale 4:[400/2000]\n",
      "scale 4:[425/2000]\n",
      "scale 4:[450/2000]\n",
      "scale 4:[475/2000]\n",
      "scale 4:[500/2000]\n",
      "scale 4:[525/2000]\n",
      "scale 4:[550/2000]\n",
      "scale 4:[575/2000]\n",
      "scale 4:[600/2000]\n",
      "scale 4:[625/2000]\n",
      "scale 4:[650/2000]\n",
      "scale 4:[675/2000]\n",
      "scale 4:[700/2000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale 4:[725/2000]\n",
      "scale 4:[750/2000]\n",
      "scale 4:[775/2000]\n",
      "scale 4:[800/2000]\n",
      "scale 4:[825/2000]\n",
      "scale 4:[850/2000]\n",
      "scale 4:[875/2000]\n",
      "scale 4:[900/2000]\n",
      "scale 4:[925/2000]\n",
      "scale 4:[950/2000]\n",
      "scale 4:[975/2000]\n",
      "scale 4:[1000/2000]\n",
      "scale 4:[1025/2000]\n",
      "scale 4:[1050/2000]\n",
      "scale 4:[1075/2000]\n",
      "scale 4:[1100/2000]\n",
      "scale 4:[1125/2000]\n",
      "scale 4:[1150/2000]\n",
      "scale 4:[1175/2000]\n",
      "scale 4:[1200/2000]\n",
      "scale 4:[1225/2000]\n",
      "scale 4:[1250/2000]\n",
      "scale 4:[1275/2000]\n",
      "scale 4:[1300/2000]\n",
      "scale 4:[1325/2000]\n",
      "scale 4:[1350/2000]\n",
      "scale 4:[1375/2000]\n",
      "scale 4:[1400/2000]\n",
      "scale 4:[1425/2000]\n",
      "scale 4:[1450/2000]\n",
      "scale 4:[1475/2000]\n",
      "scale 4:[1500/2000]\n",
      "scale 4:[1525/2000]\n",
      "scale 4:[1550/2000]\n",
      "scale 4:[1575/2000]\n",
      "scale 4:[1600/2000]\n",
      "scale 4:[1625/2000]\n",
      "scale 4:[1650/2000]\n",
      "scale 4:[1675/2000]\n",
      "scale 4:[1700/2000]\n",
      "scale 4:[1725/2000]\n",
      "scale 4:[1750/2000]\n",
      "scale 4:[1775/2000]\n",
      "scale 4:[1800/2000]\n",
      "scale 4:[1825/2000]\n",
      "scale 4:[1850/2000]\n",
      "scale 4:[1875/2000]\n",
      "scale 4:[1900/2000]\n",
      "scale 4:[1925/2000]\n",
      "scale 4:[1950/2000]\n",
      "scale 4:[1975/2000]\n",
      "scale 4:[1999/2000]\n",
      "GeneratorConcatSkip2CleanAdd(\n",
      "  (head): ConvBlock(\n",
      "    (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (body): Sequential(\n",
      "    (block1): ConvBlock(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (block2): ConvBlock(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (block3): ConvBlock(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (tail): Sequential(\n",
      "    (0): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): Tanh()\n",
      "  )\n",
      ")\n",
      "WDiscriminator(\n",
      "  (head): ConvBlock(\n",
      "    (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (body): Sequential(\n",
      "    (block1): ConvBlock(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (block2): ConvBlock(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (block3): ConvBlock(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (tail): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1))\n",
      ")\n",
      "scale 5:[0/2000]\n",
      "scale 5:[25/2000]\n",
      "scale 5:[50/2000]\n",
      "scale 5:[75/2000]\n",
      "scale 5:[100/2000]\n",
      "scale 5:[125/2000]\n",
      "scale 5:[150/2000]\n",
      "scale 5:[175/2000]\n",
      "scale 5:[200/2000]\n",
      "scale 5:[225/2000]\n",
      "scale 5:[250/2000]\n",
      "scale 5:[275/2000]\n",
      "scale 5:[300/2000]\n",
      "scale 5:[325/2000]\n",
      "scale 5:[350/2000]\n",
      "scale 5:[375/2000]\n",
      "scale 5:[400/2000]\n",
      "scale 5:[425/2000]\n",
      "scale 5:[450/2000]\n",
      "scale 5:[475/2000]\n",
      "scale 5:[500/2000]\n",
      "scale 5:[525/2000]\n",
      "scale 5:[550/2000]\n",
      "scale 5:[575/2000]\n",
      "scale 5:[600/2000]\n",
      "scale 5:[625/2000]\n",
      "scale 5:[650/2000]\n",
      "scale 5:[675/2000]\n",
      "scale 5:[700/2000]\n",
      "scale 5:[725/2000]\n",
      "scale 5:[750/2000]\n",
      "scale 5:[775/2000]\n",
      "scale 5:[800/2000]\n",
      "scale 5:[825/2000]\n",
      "scale 5:[850/2000]\n",
      "scale 5:[875/2000]\n",
      "scale 5:[900/2000]\n",
      "scale 5:[925/2000]\n",
      "scale 5:[950/2000]\n",
      "scale 5:[975/2000]\n",
      "scale 5:[1000/2000]\n",
      "scale 5:[1025/2000]\n",
      "scale 5:[1050/2000]\n",
      "scale 5:[1075/2000]\n",
      "scale 5:[1100/2000]\n",
      "scale 5:[1125/2000]\n",
      "scale 5:[1150/2000]\n",
      "scale 5:[1175/2000]\n",
      "scale 5:[1200/2000]\n",
      "scale 5:[1225/2000]\n",
      "scale 5:[1250/2000]\n",
      "scale 5:[1275/2000]\n",
      "scale 5:[1300/2000]\n",
      "scale 5:[1325/2000]\n",
      "scale 5:[1350/2000]\n",
      "scale 5:[1375/2000]\n",
      "scale 5:[1400/2000]\n",
      "scale 5:[1425/2000]\n",
      "scale 5:[1450/2000]\n",
      "scale 5:[1475/2000]\n",
      "scale 5:[1500/2000]\n",
      "scale 5:[1525/2000]\n",
      "scale 5:[1550/2000]\n",
      "scale 5:[1575/2000]\n",
      "scale 5:[1600/2000]\n",
      "scale 5:[1625/2000]\n",
      "scale 5:[1650/2000]\n",
      "scale 5:[1675/2000]\n",
      "scale 5:[1700/2000]\n",
      "scale 5:[1725/2000]\n",
      "scale 5:[1750/2000]\n",
      "scale 5:[1775/2000]\n",
      "scale 5:[1800/2000]\n",
      "scale 5:[1825/2000]\n",
      "scale 5:[1850/2000]\n",
      "scale 5:[1875/2000]\n",
      "scale 5:[1900/2000]\n",
      "scale 5:[1925/2000]\n",
      "scale 5:[1950/2000]\n",
      "scale 5:[1975/2000]\n",
      "scale 5:[1999/2000]\n",
      "GeneratorConcatSkip2CleanAdd(\n",
      "  (head): ConvBlock(\n",
      "    (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (body): Sequential(\n",
      "    (block1): ConvBlock(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (block2): ConvBlock(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (block3): ConvBlock(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (tail): Sequential(\n",
      "    (0): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): Tanh()\n",
      "  )\n",
      ")\n",
      "WDiscriminator(\n",
      "  (head): ConvBlock(\n",
      "    (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (body): Sequential(\n",
      "    (block1): ConvBlock(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (block2): ConvBlock(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (block3): ConvBlock(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (tail): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1))\n",
      ")\n",
      "scale 6:[0/2000]\n",
      "scale 6:[25/2000]\n",
      "scale 6:[50/2000]\n",
      "scale 6:[75/2000]\n",
      "scale 6:[100/2000]\n",
      "scale 6:[125/2000]\n",
      "scale 6:[150/2000]\n",
      "scale 6:[175/2000]\n",
      "scale 6:[200/2000]\n",
      "scale 6:[225/2000]\n",
      "scale 6:[250/2000]\n",
      "scale 6:[275/2000]\n",
      "scale 6:[300/2000]\n",
      "scale 6:[325/2000]\n",
      "scale 6:[350/2000]\n",
      "scale 6:[375/2000]\n",
      "scale 6:[400/2000]\n",
      "scale 6:[425/2000]\n",
      "scale 6:[450/2000]\n",
      "scale 6:[475/2000]\n",
      "scale 6:[500/2000]\n",
      "scale 6:[525/2000]\n",
      "scale 6:[550/2000]\n",
      "scale 6:[575/2000]\n",
      "scale 6:[600/2000]\n",
      "scale 6:[625/2000]\n",
      "scale 6:[650/2000]\n",
      "scale 6:[675/2000]\n",
      "scale 6:[700/2000]\n",
      "scale 6:[725/2000]\n",
      "scale 6:[750/2000]\n",
      "scale 6:[775/2000]\n",
      "scale 6:[800/2000]\n",
      "scale 6:[825/2000]\n",
      "scale 6:[850/2000]\n",
      "scale 6:[875/2000]\n",
      "scale 6:[900/2000]\n",
      "scale 6:[925/2000]\n",
      "scale 6:[950/2000]\n",
      "scale 6:[975/2000]\n",
      "scale 6:[1000/2000]\n",
      "scale 6:[1025/2000]\n",
      "scale 6:[1050/2000]\n",
      "scale 6:[1075/2000]\n",
      "scale 6:[1100/2000]\n",
      "scale 6:[1125/2000]\n",
      "scale 6:[1150/2000]\n",
      "scale 6:[1175/2000]\n",
      "scale 6:[1200/2000]\n",
      "scale 6:[1225/2000]\n",
      "scale 6:[1250/2000]\n",
      "scale 6:[1275/2000]\n",
      "scale 6:[1300/2000]\n",
      "scale 6:[1325/2000]\n",
      "scale 6:[1350/2000]\n",
      "scale 6:[1375/2000]\n",
      "scale 6:[1400/2000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale 6:[1425/2000]\n",
      "scale 6:[1450/2000]\n",
      "scale 6:[1475/2000]\n",
      "scale 6:[1500/2000]\n",
      "scale 6:[1525/2000]\n",
      "scale 6:[1550/2000]\n",
      "scale 6:[1575/2000]\n",
      "scale 6:[1600/2000]\n",
      "scale 6:[1625/2000]\n",
      "scale 6:[1650/2000]\n",
      "scale 6:[1675/2000]\n",
      "scale 6:[1700/2000]\n",
      "scale 6:[1725/2000]\n",
      "scale 6:[1750/2000]\n",
      "scale 6:[1775/2000]\n",
      "scale 6:[1800/2000]\n",
      "scale 6:[1825/2000]\n",
      "scale 6:[1850/2000]\n",
      "scale 6:[1875/2000]\n",
      "scale 6:[1900/2000]\n",
      "scale 6:[1925/2000]\n",
      "scale 6:[1950/2000]\n",
      "scale 6:[1975/2000]\n",
      "scale 6:[1999/2000]\n",
      "GeneratorConcatSkip2CleanAdd(\n",
      "  (head): ConvBlock(\n",
      "    (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (body): Sequential(\n",
      "    (block1): ConvBlock(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (block2): ConvBlock(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (block3): ConvBlock(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (tail): Sequential(\n",
      "    (0): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): Tanh()\n",
      "  )\n",
      ")\n",
      "WDiscriminator(\n",
      "  (head): ConvBlock(\n",
      "    (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (body): Sequential(\n",
      "    (block1): ConvBlock(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (block2): ConvBlock(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (block3): ConvBlock(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (LeakyRelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (tail): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1))\n",
      ")\n",
      "scale 7:[0/2000]\n",
      "scale 7:[25/2000]\n",
      "scale 7:[50/2000]\n",
      "scale 7:[75/2000]\n",
      "scale 7:[100/2000]\n",
      "scale 7:[125/2000]\n",
      "scale 7:[150/2000]\n",
      "scale 7:[175/2000]\n",
      "scale 7:[200/2000]\n",
      "scale 7:[225/2000]\n",
      "scale 7:[250/2000]\n",
      "scale 7:[275/2000]\n",
      "scale 7:[300/2000]\n",
      "scale 7:[325/2000]\n",
      "scale 7:[350/2000]\n",
      "scale 7:[375/2000]\n",
      "scale 7:[400/2000]\n",
      "scale 7:[425/2000]\n",
      "scale 7:[450/2000]\n",
      "scale 7:[475/2000]\n",
      "scale 7:[500/2000]\n",
      "scale 7:[525/2000]\n",
      "scale 7:[550/2000]\n",
      "scale 7:[575/2000]\n",
      "scale 7:[600/2000]\n",
      "scale 7:[625/2000]\n",
      "scale 7:[650/2000]\n",
      "scale 7:[675/2000]\n",
      "scale 7:[700/2000]\n",
      "scale 7:[725/2000]\n",
      "scale 7:[750/2000]\n",
      "scale 7:[775/2000]\n",
      "scale 7:[800/2000]\n",
      "scale 7:[825/2000]\n",
      "scale 7:[850/2000]\n",
      "scale 7:[875/2000]\n",
      "scale 7:[900/2000]\n",
      "scale 7:[925/2000]\n",
      "scale 7:[950/2000]\n",
      "scale 7:[975/2000]\n",
      "scale 7:[1000/2000]\n",
      "scale 7:[1025/2000]\n",
      "scale 7:[1050/2000]\n",
      "scale 7:[1075/2000]\n",
      "scale 7:[1100/2000]\n",
      "scale 7:[1125/2000]\n",
      "scale 7:[1150/2000]\n",
      "scale 7:[1175/2000]\n",
      "scale 7:[1200/2000]\n",
      "scale 7:[1225/2000]\n",
      "scale 7:[1250/2000]\n",
      "scale 7:[1275/2000]\n",
      "scale 7:[1300/2000]\n",
      "scale 7:[1325/2000]\n",
      "scale 7:[1350/2000]\n",
      "scale 7:[1375/2000]\n",
      "scale 7:[1400/2000]\n",
      "scale 7:[1425/2000]\n",
      "scale 7:[1450/2000]\n",
      "scale 7:[1475/2000]\n",
      "scale 7:[1500/2000]\n",
      "scale 7:[1525/2000]\n",
      "scale 7:[1550/2000]\n",
      "scale 7:[1575/2000]\n",
      "scale 7:[1600/2000]\n",
      "scale 7:[1625/2000]\n",
      "scale 7:[1650/2000]\n",
      "scale 7:[1675/2000]\n",
      "scale 7:[1700/2000]\n",
      "scale 7:[1725/2000]\n",
      "scale 7:[1750/2000]\n",
      "scale 7:[1775/2000]\n",
      "scale 7:[1800/2000]\n",
      "scale 7:[1825/2000]\n",
      "scale 7:[1850/2000]\n",
      "scale 7:[1875/2000]\n",
      "scale 7:[1900/2000]\n",
      "scale 7:[1925/2000]\n",
      "scale 7:[1950/2000]\n",
      "scale 7:[1975/2000]\n",
      "scale 7:[1999/2000]\n",
      "4.000000\n"
     ]
    }
   ],
   "source": [
    "!python SR.py --input_name 0.png --not_cuda"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The above process takes 1 image and trains on it till optimised resolution is reached. Due to the resources required for each image to be processed we have continued with the original resolution instead of increasing it. However, theoretically this process should increase the accuracy of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection using YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'yolov5' already exists and is not an empty directory.\n",
      "Requirement already satisfied: matplotlib in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (3.7.5)\n",
      "Requirement already satisfied: scikit-image in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (0.16.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (1.3.2)\n",
      "Requirement already satisfied: scipy in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (1.10.1)\n",
      "Requirement already satisfied: numpy in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (1.24.4)\n",
      "Requirement already satisfied: torch in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (1.8.0)\n",
      "Requirement already satisfied: torchvision in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (0.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 1)) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 1)) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 1)) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 1)) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 1)) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 1)) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 1)) (5.7.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from scikit-image->-r requirements.txt (line 2)) (2.4)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from scikit-image->-r requirements.txt (line 2)) (2.9.0)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from scikit-image->-r requirements.txt (line 2)) (1.1.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->-r requirements.txt (line 3)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->-r requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from torch->-r requirements.txt (line 6)) (4.12.2)\n",
      "Requirement already satisfied: six in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->-r requirements.txt (line 1)) (1.15.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib->-r requirements.txt (line 1)) (3.1.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/bhavnasharma/opt/anaconda3/lib/python3.8/site-packages (from networkx>=2.0->scikit-image->-r requirements.txt (line 2)) (4.4.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5.git \n",
    "!cd yolov5\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Train-Test with a 80/20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 40 images, Test set: 10 images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "def split_dataset(images_dir, labels_dir, train_images_dir, train_labels_dir, test_images_dir, test_labels_dir, train_ratio=0.8):\n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(train_images_dir, exist_ok=True)\n",
    "    os.makedirs(train_labels_dir, exist_ok=True)\n",
    "    os.makedirs(test_images_dir, exist_ok=True)\n",
    "    os.makedirs(test_labels_dir, exist_ok=True)\n",
    "\n",
    "    image_files = [f for f in os.listdir(images_dir) if f.endswith('.png')]\n",
    "    random.shuffle(image_files)\n",
    "\n",
    "    # Split the data\n",
    "    train_size = int(len(image_files) * train_ratio)\n",
    "    train_files = image_files[:train_size]\n",
    "    test_files = image_files[train_size:]\n",
    "\n",
    "    # Move the files \n",
    "    for file in train_files:\n",
    "        shutil.move(os.path.join(images_dir, file), os.path.join(train_images_dir, file))\n",
    "        shutil.move(os.path.join(labels_dir, file.replace('.png', '.txt')), os.path.join(train_labels_dir, file.replace('.png', '.txt')))\n",
    "\n",
    "    for file in test_files:\n",
    "        shutil.move(os.path.join(images_dir, file), os.path.join(test_images_dir, file))\n",
    "        shutil.move(os.path.join(labels_dir, file.replace('.png', '.txt')), os.path.join(test_labels_dir, file.replace('.png', '.txt')))\n",
    "\n",
    "    print(f\"Train set: {len(train_files)} images, Test set: {len(test_files)} images\")\n",
    "\n",
    "# Define directories\n",
    "images_dir = \"/Users/bhavnasharma/Downloads/SinGAN/Results/images\"\n",
    "labels_dir = \"/Users/bhavnasharma/Downloads/SinGAN/Results/labels\"\n",
    "train_images_dir = \"/Users/bhavnasharma/Downloads/SinGAN/Results/train/images\"\n",
    "train_labels_dir = \"/Users/bhavnasharma/Downloads/SinGAN/Results/train/labels\"\n",
    "test_images_dir = \"/Users/bhavnasharma/Downloads/SinGAN/Results/test/images\"\n",
    "test_labels_dir = \"/Users/bhavnasharma/Downloads/SinGAN/Results/test/labels\"\n",
    "\n",
    "split_dataset(images_dir, labels_dir, train_images_dir, train_labels_dir, test_images_dir, test_labels_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files moved successfully!\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Define source and destination\n",
    "train_images_src = \"/Users/bhavnasharma/Downloads/SinGAN/Results/train/images\"\n",
    "train_labels_src = \"/Users/bhavnasharma/Downloads/SinGAN/Results/train/labels\"\n",
    "test_images_src = \"/Users/bhavnasharma/Downloads/SinGAN/Results/test/images\"\n",
    "test_labels_src = \"/Users/bhavnasharma/Downloads/SinGAN/Results/test/labels\"\n",
    "\n",
    "train_images_dst = \"/Users/bhavnasharma/Downloads/SinGAN/yolov5/data/images/train\"\n",
    "train_labels_dst = \"/Users/bhavnasharma/Downloads/SinGAN/yolov5/data/labels/train\"\n",
    "val_images_dst = \"/Users/bhavnasharma/Downloads/SinGAN/yolov5/data/images/val\"\n",
    "val_labels_dst = \"/Users/bhavnasharma/Downloads/SinGAN/yolov5/data/labels/val\"\n",
    "\n",
    "os.makedirs(train_images_dst, exist_ok=True)\n",
    "os.makedirs(train_labels_dst, exist_ok=True)\n",
    "os.makedirs(val_images_dst, exist_ok=True)\n",
    "os.makedirs(val_labels_dst, exist_ok=True)\n",
    "\n",
    "for file_name in os.listdir(train_images_src):\n",
    "    shutil.move(os.path.join(train_images_src, file_name), os.path.join(train_images_dst, file_name))\n",
    "\n",
    "for file_name in os.listdir(train_labels_src):\n",
    "    shutil.move(os.path.join(train_labels_src, file_name), os.path.join(train_labels_dst, file_name))\n",
    "\n",
    "for file_name in os.listdir(test_images_src):\n",
    "    shutil.move(os.path.join(test_images_src, file_name), os.path.join(val_images_dst, file_name))\n",
    "\n",
    "for file_name in os.listdir(test_labels_src):\n",
    "    shutil.move(os.path.join(test_labels_src, file_name), os.path.join(val_labels_dst, file_name))\n",
    "\n",
    "print(\"Files moved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bhavnasharma/Downloads/SinGAN/yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/bhavnasharma/Downloads/SinGAN/yolov5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test YOLO performance on entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/Users/bhavnasharma/Downloads/SinGAN/yolov5/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=cpu, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
      "YOLOv5 🚀 v7.0-389-ge62a31b6 Python-3.8.3 torch-1.8.0 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/bhavnasharma/Downloads/SinGAN/yolov5/data/labels/train...\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/bhavnasharma/Downloads/SinGAN/yolov5/data/labels/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/bhavnasharma/Downloads/SinGAN/yolov5/data/labels/val...:   \u001b[0mError decoding JSON from /Users/bhavnasharma/Library/Application Support/Ultralytics/settings.json. Starting with an empty dictionary.\n",
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/Users/bhavnasharma/Library/Application Support/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/bhavnasharma/Downloads/SinGAN/yolov5/data/labels/val... 18 \u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/bhavnasharma/Downloads/SinGAN/yolov5/data/labels/val.cache\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.68 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Plotting labels to runs/train/exp3/labels.jpg... \n",
      "Error decoding JSON from /Users/bhavnasharma/Library/Application Support/Ultralytics/settings.json. Starting with an empty dictionary.\n",
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/Users/bhavnasharma/Library/Application Support/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp3\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       0/49         0G     0.1246    0.04501          0         84        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45    0.00407      0.489    0.00493   0.000981\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       1/49         0G     0.1198    0.04742          0        110        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45    0.00925        0.4      0.008    0.00151\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       2/49         0G     0.1139    0.04754          0         71        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45    0.00886        0.6     0.0164    0.00332\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       3/49         0G     0.1062    0.05443          0         87        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.011      0.578     0.0266    0.00546\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       4/49         0G     0.0996    0.05582          0         92        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45     0.0288      0.444     0.0451     0.0124\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       5/49         0G    0.09346    0.05572          0         82        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45     0.0782      0.347     0.0888     0.0243\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       6/49         0G    0.08863    0.05553          0         76        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45     0.0998     0.0667     0.0923     0.0296\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       7/49         0G    0.08898    0.06373          0         94        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.217      0.156      0.158     0.0411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       8/49         0G    0.08726    0.05794          0         83        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.241      0.578      0.214     0.0587\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       9/49         0G    0.08188    0.05702          0         91        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.316      0.617      0.277     0.0838\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      10/49         0G    0.07923    0.05833          0        102        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.473      0.644      0.488      0.142\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      11/49         0G    0.07635    0.05259          0         72        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.104      0.178     0.0682     0.0168\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      12/49         0G    0.07492    0.05294          0         95        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45     0.0696      0.289     0.0538     0.0148\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      13/49         0G    0.07518    0.05423          0         99        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.532      0.607      0.643      0.163\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      14/49         0G    0.06407    0.05126          0         77        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45     0.0738      0.578     0.0656     0.0212\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      15/49         0G    0.07619    0.04348          0         95        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.238      0.511       0.29     0.0861\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      16/49         0G    0.06477    0.04581          0         68        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.521      0.507      0.515      0.201\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      17/49         0G    0.06688    0.04187          0         91        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.457      0.542       0.46      0.161\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      18/49         0G     0.0653     0.0457          0         78        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.577      0.607      0.656      0.281\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      19/49         0G    0.06255    0.04688          0        107        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.404      0.557      0.441       0.15\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      20/49         0G    0.06506    0.04567          0         92        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.758      0.733      0.773      0.302\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      21/49         0G     0.0602    0.04436          0         97        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.574      0.733      0.655      0.239\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      22/49         0G     0.0604    0.03662          0         98        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.718      0.756      0.806      0.304\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      23/49         0G    0.05723    0.03966          0         97        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.661      0.711      0.731      0.263\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      24/49         0G    0.06127    0.03846          0         92        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.769      0.739      0.838      0.397\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      25/49         0G    0.05471    0.03667          0         92        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.739        0.8      0.836       0.39\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      26/49         0G    0.05296    0.03444          0         94        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.569      0.689      0.706      0.281\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      27/49         0G    0.05901    0.03803          0         96        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45       0.57      0.824      0.648      0.301\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      28/49         0G     0.0523    0.03418          0         80        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45       0.57      0.824      0.648      0.301\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      29/49         0G    0.05358    0.03714          0        107        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45       0.62      0.822      0.783      0.441\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      30/49         0G    0.05071    0.03478          0         80        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.605      0.815       0.73      0.354\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      31/49         0G    0.05011    0.03652          0         88        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.653        0.8      0.815      0.447\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      32/49         0G    0.05262    0.03465          0         79        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.653        0.8      0.815      0.447\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      33/49         0G    0.04938    0.03133          0        105        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.767       0.88      0.854       0.39\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      34/49         0G     0.0502    0.03135          0         88        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45       0.45        0.8      0.557      0.265\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      35/49         0G    0.05674    0.03211          0         97        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.599      0.864      0.693      0.298\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      36/49         0G    0.04999    0.03187          0         87        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.599      0.864      0.693      0.298\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      37/49         0G    0.04441    0.03428          0        103        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.703       0.84      0.845       0.56\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      38/49         0G     0.0434    0.03074          0         92        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.695      0.889      0.857       0.46\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      39/49         0G    0.05117      0.031          0         88        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.825      0.867      0.916      0.609\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      40/49         0G    0.03933    0.03464          0        115        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.825      0.867      0.916      0.609\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      41/49         0G    0.04035    0.03278          0        116        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.653      0.822      0.823      0.497\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      42/49         0G    0.03861    0.03207          0        117        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.938      0.933      0.968       0.69\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      43/49         0G    0.03717     0.0274          0         87        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.806      0.889      0.917      0.582\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      44/49         0G    0.03883    0.02946          0        109        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.806      0.889      0.917      0.582\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      45/49         0G    0.03542    0.03276          0        108        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.915      0.954      0.952      0.705\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      46/49         0G    0.03396    0.02711          0         90        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45       0.95      0.933      0.985      0.642\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      47/49         0G    0.03519    0.02786          0         94        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.998      0.978      0.991      0.702\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      48/49         0G    0.03246    0.03152          0         91        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.998      0.978      0.991      0.702\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      49/49         0G      0.032    0.02959          0         94        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.978      0.974       0.99      0.736\n",
      "\n",
      "50 epochs completed in 1.071 hours.\n",
      "Optimizer stripped from runs/train/exp3/weights/last.pt, 14.3MB\n",
      "Optimizer stripped from runs/train/exp3/weights/best.pt, 14.3MB\n",
      "\n",
      "Validating runs/train/exp3/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.978      0.974       0.99      0.736\n",
      "Results saved to \u001b[1mruns/train/exp3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 640 --batch 16 --epochs 50 --data /Users/bhavnasharma/Downloads/SinGAN/yolov5/data.yaml --weights yolov5s.pt --device cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/Users/bhavnasharma/Downloads/SinGAN/yolov5/data.yaml, weights=['/Users/bhavnasharma/Downloads/SinGAN/yolov5/runs/train/exp3/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
      "YOLOv5 🚀 v7.0-389-ge62a31b6 Python-3.8.3 torch-1.8.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/bhavnasharma/Downloads/SinGAN/yolov5/data/labels/val.cache.\u001b[0m\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.978      0.975       0.99      0.736\n",
      "Speed: 1.2ms pre-process, 141.7ms inference, 2.5ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/exp2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python val.py --weights /Users/bhavnasharma/Downloads/SinGAN/yolov5/runs/train/exp3/weights/best.pt --data /Users/bhavnasharma/Downloads/SinGAN/yolov5/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/Users/bhavnasharma/Downloads/SinGAN/yolov5/data.yaml, weights=['/Users/bhavnasharma/Downloads/SinGAN/yolov5/runs/train/exp3/weights/last.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
      "YOLOv5 🚀 v7.0-389-ge62a31b6 Python-3.8.3 torch-1.8.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/bhavnasharma/Downloads/SinGAN/yolov5/data/labels/val.cache.\u001b[0m\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         18         45      0.978      0.975       0.99      0.736\n",
      "Speed: 1.2ms pre-process, 168.4ms inference, 1.6ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/exp3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python val.py --weights /Users/bhavnasharma/Downloads/SinGAN/yolov5/runs/train/exp3/weights/last.pt --data /Users/bhavnasharma/Downloads/SinGAN/yolov5/data.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset to show that increasing number of images is improving our performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Added to images/train_100.0\n",
      "12\n",
      "Added to images/train_250.0\n",
      "24\n",
      "Added to images/train_500.0\n",
      "36\n",
      "Added to images/train_750.0\n",
      "49\n",
      "Added to images/train_1000.0\n",
      "Dataset subsets created!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Parameters\n",
    "split_ratios = [0.1, 0.25, 0.5, 0.75, 1.0]  # 10%, 25%, 50%, 75%, 100%\n",
    "images_dir = \"/Users/bhavnasharma/Downloads/SinGAN/yolov5/data/images/train\"\n",
    "labels_dir = \"/Users/bhavnasharma/Downloads/SinGAN/yolov5/data/labels/train\"\n",
    "base_dir = \"/Users/bhavnasharma/Downloads/SinGAN/yolov5/data\"\n",
    "\n",
    "image_files = [f for f in os.listdir(images_dir) if f.endswith('.png')]\n",
    "\n",
    "random.shuffle(image_files)\n",
    "\n",
    "for ratio in split_ratios:\n",
    "    size = int(len(image_files) * ratio)\n",
    "    print(size)\n",
    "    subset = image_files[:size]\n",
    "    train_images_dir = os.path.join(base_dir, f'images/train_{int(ratio*1000)}')\n",
    "    train_labels_dir = os.path.join(base_dir, f'labels/train_{int(ratio*1000)}')\n",
    "    print(\"Added to\", f'images/train_{ratio*1000}')\n",
    "    \n",
    "    os.makedirs(train_images_dir, exist_ok=True)\n",
    "    os.makedirs(train_labels_dir, exist_ok=True)\n",
    "    \n",
    "    for file in subset:\n",
    "        shutil.copy(os.path.join(images_dir, file), os.path.join(train_images_dir, file))\n",
    "        shutil.copy(os.path.join(labels_dir, file.replace('.png', '.txt')), os.path.join(train_labels_dir, file.replace('.png', '.txt')))\n",
    "\n",
    "print(\"Dataset subsets created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.yaml files created for each subset!\n"
     ]
    }
   ],
   "source": [
    "base_dir = '/Users/bhavnasharma/Downloads/SinGAN/yolov5/data'\n",
    "val_images_dir = \"/Users/bhavnasharma/Downloads/SinGAN/yolov5/data/images/val\"\n",
    "subsets = [100, 250, 500, 750, 1000]\n",
    "\n",
    "for size in subsets:\n",
    "    data_yaml_content = f\"\"\"\n",
    "    train: {base_dir}/images/train_{size}\n",
    "    val: {val_images_dir}\n",
    "\n",
    "    # Classes\n",
    "    nc: 1  # number of classes\n",
    "    names: ['Pedestrian']\n",
    "    \"\"\"\n",
    "    with open(f'data_{size}.yaml', 'w') as file:\n",
    "        file.write(data_yaml_content.strip())\n",
    "\n",
    "print(\"data.yaml files created for each subset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on smaller datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/Users/bhavnasharma/Downloads/SinGAN/yolov5/data_100.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=cpu, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
      "YOLOv5 🚀 v7.0-389-ge62a31b6 Python-3.8.3 torch-1.8.0 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/bhavnasharma/Downloads/SinGAN/yolov5/data/labels/train_10\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/bhavnasharma/Downloads/SinGAN/yolov5/data/labels/train_100.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/bhavnasharma/Downloads/SinGAN/yolov5/data/labels/val... 24 \u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/bhavnasharma/Downloads/SinGAN/yolov5/data/labels/val.cache\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.62 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Plotting labels to runs/train/exp21/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp21\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       0/49         0G     0.1279    0.04897          0         29        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00258      0.304    0.00261   0.000655\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       1/49         0G      0.127    0.04944          0         27        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00319      0.393    0.00535   0.000857\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       2/49         0G     0.1235    0.04736          0         23        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00304      0.375    0.00447   0.000823\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       3/49         0G     0.1236    0.04781          0         24        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00319      0.393      0.004   0.000772\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       4/49         0G     0.1238    0.05352          0         30        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00425      0.339    0.00452   0.000862\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       5/49         0G     0.1247    0.05288          0         29        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00333      0.393    0.00386   0.000778\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       6/49         0G     0.1258    0.04815          0         24        640: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00333      0.357    0.00362   0.000782\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       7/49         0G      0.119    0.05246          0         25        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00319      0.393    0.00343   0.000729\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       8/49         0G     0.1216    0.05143          0         28        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00361      0.464    0.00435   0.000903\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       9/49         0G     0.1248    0.03992          0         18        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00361      0.464    0.00458   0.000974\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      10/49         0G     0.1187    0.06035          0         34        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00433      0.464    0.00506    0.00107\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      11/49         0G     0.1189    0.04735          0         22        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00379      0.446    0.00474    0.00113\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      12/49         0G      0.122    0.05511          0         30        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00391      0.482    0.00534    0.00127\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      13/49         0G     0.1159     0.0732          0         39        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00389        0.5    0.00532    0.00143\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      14/49         0G     0.1218    0.04932          0         25        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00563      0.464    0.00603    0.00156\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      15/49         0G     0.1165     0.0543          0         28        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00514      0.464    0.00754    0.00173\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      16/49         0G     0.1113    0.04962          0         20        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0089      0.304    0.00897    0.00186\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      17/49         0G     0.1152    0.03892          0         15        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00863      0.286    0.00864    0.00186\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      18/49         0G     0.1137     0.0641          0         34        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00884      0.321    0.00993    0.00214\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      19/49         0G     0.1135    0.05391          0         26        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00884      0.321    0.00993    0.00214\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      20/49         0G     0.1098     0.0506          0         22        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00814      0.411     0.0108    0.00225\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      21/49         0G     0.1079      0.056          0         26        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00814      0.411     0.0108    0.00225\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      22/49         0G     0.1141    0.04992          0         26        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.008      0.571     0.0137    0.00268\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      23/49         0G     0.1107    0.04693          0         21        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.008      0.571     0.0137    0.00268\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      24/49         0G     0.1125    0.05077          0         24        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00873      0.518     0.0134    0.00278\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      25/49         0G     0.1076    0.06052          0         29        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00873      0.518     0.0134    0.00278\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      26/49         0G     0.1026     0.0578          0         24        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00937      0.607      0.016    0.00333\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      27/49         0G     0.1097    0.06052          0         31        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00937      0.607      0.016    0.00333\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      28/49         0G     0.1024    0.04712          0         18        640: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00922      0.482     0.0163    0.00363\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      29/49         0G     0.1038    0.06312          0         28        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00922      0.482     0.0163    0.00363\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      30/49         0G      0.104    0.04827          0         20        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0105      0.536     0.0215    0.00458\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      31/49         0G      0.103    0.06925          0         29        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0105      0.536     0.0215    0.00458\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      32/49         0G     0.1038    0.05894          0         27        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0133      0.411     0.0247     0.0048\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      33/49         0G      0.105    0.04224          0         16        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0133      0.411     0.0247     0.0048\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      34/49         0G     0.1005    0.05824          0         24        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.013      0.411     0.0221    0.00487\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      35/49         0G     0.1004      0.073          0         33        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.013      0.411     0.0221    0.00487\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      36/49         0G    0.09977    0.03687          0         12        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0164      0.446     0.0227    0.00578\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      37/49         0G     0.1083     0.0338          0         12        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0164      0.446     0.0227    0.00578\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      38/49         0G     0.1062    0.06122          0         29        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0212      0.464     0.0229    0.00621\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      39/49         0G     0.1049    0.05277          0         26        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0212      0.464     0.0229    0.00621\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      40/49         0G      0.103    0.05916          0         26        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0232      0.446     0.0239    0.00606\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      41/49         0G     0.1014    0.06899          0         30        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0232      0.446     0.0239    0.00606\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      42/49         0G     0.1049    0.04822          0         21        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0269      0.446     0.0243    0.00627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      43/49         0G    0.09994    0.07267          0         33        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0269      0.446     0.0243    0.00627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      44/49         0G     0.1005    0.07986          0         36        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0269      0.446     0.0258    0.00657\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      45/49         0G      0.106    0.06724          0         32        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0269      0.446     0.0258    0.00657\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      46/49         0G      0.103    0.04432          0         19        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0271      0.393     0.0277    0.00704\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      47/49         0G    0.09728    0.09098          0         39        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0271      0.393     0.0277    0.00704\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      48/49         0G    0.09929    0.07088          0         29        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0323      0.321     0.0295    0.00738\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      49/49         0G    0.09365    0.05697          0         22        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0323      0.321     0.0295    0.00738\n",
      "\n",
      "50 epochs completed in 0.160 hours.\n",
      "Optimizer stripped from runs/train/exp21/weights/last.pt, 14.3MB\n",
      "Optimizer stripped from runs/train/exp21/weights/best.pt, 14.3MB\n",
      "\n",
      "Validating runs/train/exp21/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0347      0.321       0.03    0.00753\n",
      "Results saved to \u001b[1mruns/train/exp21\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/Users/bhavnasharma/Downloads/SinGAN/yolov5/data_250.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=cpu, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
      "YOLOv5 🚀 v7.0-389-ge62a31b6 Python-3.8.3 torch-1.8.0 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/bhavnasharma/Downloads/SinGAN/yolov5/data/labels/train_25\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/bhavnasharma/Downloads/SinGAN/yolov5/data/labels/train_250.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/bhavnasharma/Downloads/SinGAN/yolov5/data/labels/val.cache.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.80 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Plotting labels to runs/train/exp22/labels.jpg... \n",
      "Error decoding JSON from /Users/bhavnasharma/Library/Application Support/Ultralytics/settings.json. Starting with an empty dictionary.\n",
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/Users/bhavnasharma/Library/Application Support/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "Error decoding JSON from /Users/bhavnasharma/Library/Application Support/Ultralytics/settings.json. Starting with an empty dictionary.\n",
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/Users/bhavnasharma/Library/Application Support/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "Error decoding JSON from /Users/bhavnasharma/Library/Application Support/Ultralytics/settings.json. Starting with an empty dictionary.\n",
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/Users/bhavnasharma/Library/Application Support/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp22\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       0/49         0G     0.1238     0.0511          0         84        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00264      0.339    0.00251    0.00065\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       1/49         0G     0.1258    0.04445          0         67        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00333      0.339    0.00569   0.000933\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       2/49         0G     0.1244    0.04374          0         61        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00319      0.393    0.00425   0.000794\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       3/49         0G     0.1222    0.04538          0         66        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00319      0.393    0.00425    0.00086\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       4/49         0G     0.1251    0.04766          0         77        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00333      0.375    0.00376   0.000828\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       5/49         0G     0.1219    0.05024          0         81        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00333      0.429    0.00341   0.000784\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       6/49         0G     0.1191    0.04864          0         71        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00361      0.464    0.00458    0.00104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       7/49         0G     0.1207    0.04829          0         74        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00409      0.482     0.0056    0.00123\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       8/49         0G     0.1154    0.04962          0         72        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00422      0.536    0.00686    0.00159\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       9/49         0G     0.1132    0.05151          0         70        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00562      0.482    0.00888     0.0019\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      10/49         0G     0.1125    0.04778          0         63        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00742      0.571     0.0118     0.0024\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      11/49         0G     0.1105    0.05152          0         72        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00825      0.518     0.0144    0.00296\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      12/49         0G     0.1055    0.05039          0         60        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00906      0.554     0.0162    0.00359\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      13/49         0G     0.1053    0.05533          0         70        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00949      0.518      0.017    0.00409\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      14/49         0G     0.1045    0.05538          0         69        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0362      0.125     0.0222    0.00471\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      15/49         0G     0.1001    0.07255          0         93        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0504      0.107      0.026    0.00573\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      16/49         0G    0.09757    0.05567          0         66        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0236      0.232     0.0208    0.00448\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      17/49         0G    0.09829    0.05303          0         65        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0236      0.232     0.0208    0.00448\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      18/49         0G    0.09942    0.04431          0         50        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0117      0.554     0.0222    0.00426\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      19/49         0G    0.09537     0.0641          0         82        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0117      0.554     0.0222    0.00426\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      20/49         0G    0.09735    0.05992          0         76        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0471      0.232     0.0425    0.00894\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      21/49         0G    0.09201    0.06425          0         76        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0471      0.232     0.0425    0.00894\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      22/49         0G    0.09647    0.07183          0         91        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0482       0.25      0.048     0.0122\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      23/49         0G    0.09122    0.06554          0         79        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0482       0.25      0.048     0.0122\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      24/49         0G    0.09217    0.05772          0         66        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0424      0.357      0.039    0.00942\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      25/49         0G    0.09389    0.06121          0         77        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0424      0.357      0.039    0.00942\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      26/49         0G    0.09288    0.05469          0         68        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0597      0.143     0.0567     0.0174\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      27/49         0G    0.08863    0.07151          0         84        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0597      0.143     0.0567     0.0174\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      28/49         0G    0.09385    0.05162          0         63        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.142      0.143     0.0945     0.0346\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      29/49         0G    0.09141    0.07216          0         88        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.142      0.143     0.0945     0.0346\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      30/49         0G    0.08944    0.06903          0         83        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.168     0.0893      0.106     0.0387\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      31/49         0G     0.0871    0.06452          0         76        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.168     0.0893      0.106     0.0387\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      32/49         0G    0.08938    0.05788          0         67        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.205     0.0893      0.136     0.0357\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      33/49         0G    0.08773    0.06064          0         70        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.205     0.0893      0.136     0.0357\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      34/49         0G     0.0852    0.06938          0         80        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.211      0.143      0.117     0.0322\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      35/49         0G    0.08718     0.0628          0         70        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.211      0.143      0.117     0.0322\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      36/49         0G    0.08991    0.07373          0         90        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.208      0.143      0.128     0.0334\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      37/49         0G    0.08789    0.06506          0         77        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.208      0.143      0.128     0.0334\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      38/49         0G    0.08564    0.06105          0         74        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.139       0.25       0.12     0.0286\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      39/49         0G    0.08874    0.05666          0         69        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.139       0.25       0.12     0.0286\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      40/49         0G    0.08281    0.06986          0         83        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.176      0.214      0.134     0.0348\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      41/49         0G    0.08525    0.06807          0         82        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.176      0.214      0.134     0.0348\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      42/49         0G    0.07885    0.05077          0         54        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.165      0.214      0.142     0.0351\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      43/49         0G    0.08538    0.06938          0         84        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.165      0.214      0.142     0.0351\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      44/49         0G    0.07999     0.0595          0         65        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.179      0.304      0.153     0.0425\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      45/49         0G    0.08451    0.07153          0         86        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.179      0.304      0.153     0.0425\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      46/49         0G    0.08217    0.06636          0         78        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.199      0.321       0.17     0.0507\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      47/49         0G    0.08978    0.06712          0         86        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.199      0.321       0.17     0.0507\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      48/49         0G    0.08186    0.05611          0         63        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.235      0.339      0.186      0.054\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      49/49         0G    0.08414    0.05455          0         67        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.235      0.339      0.186      0.054\n",
      "\n",
      "50 epochs completed in 0.389 hours.\n",
      "Optimizer stripped from runs/train/exp22/weights/last.pt, 14.3MB\n",
      "Optimizer stripped from runs/train/exp22/weights/best.pt, 14.3MB\n",
      "\n",
      "Validating runs/train/exp22/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.237      0.339      0.187     0.0536\n",
      "Results saved to \u001b[1mruns/train/exp22\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/Users/bhavnasharma/Downloads/SinGAN/yolov5/data_500.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=cpu, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
      "YOLOv5 🚀 v7.0-389-ge62a31b6 Python-3.8.3 torch-1.8.0 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/bhavnasharma/Downloads/SinGAN/yolov5/data/labels/train_50\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/bhavnasharma/Downloads/SinGAN/yolov5/data/labels/train_500.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/bhavnasharma/Downloads/SinGAN/yolov5/data/labels/val.cache.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.71 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Plotting labels to runs/train/exp23/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp23\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       0/49         0G     0.1248    0.04813          0         43        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00306      0.393    0.00517   0.000806\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       1/49         0G     0.1246    0.04554          0         45        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00319      0.411    0.00334   0.000764\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       2/49         0G     0.1241     0.0476          0         56        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00333      0.429    0.00398   0.000833\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       3/49         0G     0.1187    0.04686          0         39        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00361      0.464    0.00519    0.00125\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       4/49         0G     0.1141    0.04749          0         43        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00658      0.518    0.00816    0.00189\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       5/49         0G     0.1102      0.046          0         39        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00713      0.482      0.016    0.00375\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       6/49         0G     0.1066    0.06123          0         67        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00919      0.589      0.022    0.00467\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       7/49         0G     0.1013    0.06173          0         51        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00866      0.643     0.0214    0.00463\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       8/49         0G    0.09558    0.05501          0         46        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0138      0.589     0.0257    0.00541\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       9/49         0G    0.09407    0.05596          0         47        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0251      0.518     0.0344    0.00794\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      10/49         0G    0.09266     0.0601          0         49        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0173      0.625     0.0393    0.00957\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      11/49         0G    0.09012    0.06977          0         55        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0538      0.482     0.0614     0.0148\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      12/49         0G    0.08621    0.06439          0         49        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0391      0.589     0.0759     0.0206\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      13/49         0G    0.08474    0.06338          0         50        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.126      0.482      0.119      0.032\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      14/49         0G    0.08344    0.07336          0         56        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.167      0.357      0.147     0.0415\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      15/49         0G    0.08671    0.06102          0         47        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.201      0.319      0.174     0.0482\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      16/49         0G    0.07842    0.05551          0         33        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.278      0.429      0.232     0.0709\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Train the model for each dataset size\n",
    "!python train.py --img 640 --batch 16 --epochs 50 --data /Users/bhavnasharma/Downloads/SinGAN/yolov5/data_100.yaml --weights yolov5s.pt --device cpu\n",
    "!python train.py --img 640 --batch 16 --epochs 50 --data /Users/bhavnasharma/Downloads/SinGAN/yolov5/data_250.yaml --weights yolov5s.pt --device cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We stopped code after 2 models so the output above has partial result of the 3rd training. \n",
    "# 3rd model onwards training is continued in the next cell.\n",
    "# All models were saved in our yolov5 runs train file so results don't require retraining!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/Users/bhavnasharma/Downloads/SinGAN/yolov5/data_500.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=cpu, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
      "YOLOv5 🚀 v7.0-389-ge62a31b6 Python-3.8.3 torch-1.8.0 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/bhavnasharma/Downloads/SinGAN/yolov5/data/labels/train_50\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/bhavnasharma/Downloads/SinGAN/yolov5/data/labels/val.cache.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.71 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Plotting labels to runs/train/exp24/labels.jpg... \n",
      "Error decoding JSON from /Users/bhavnasharma/Library/Application Support/Ultralytics/settings.json. Starting with an empty dictionary.\n",
      "Error decoding JSON from /Users/bhavnasharma/Library/Application Support/Ultralytics/settings.json. Starting with an empty dictionary.\n",
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/Users/bhavnasharma/Library/Application Support/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/Users/bhavnasharma/Library/Application Support/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "Error decoding JSON from /Users/bhavnasharma/Library/Application Support/Ultralytics/settings.json. Starting with an empty dictionary.\n",
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/Users/bhavnasharma/Library/Application Support/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "Error decoding JSON from /Users/bhavnasharma/Library/Application Support/Ultralytics/settings.json. Starting with an empty dictionary.\n",
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/Users/bhavnasharma/Library/Application Support/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp24\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       0/49         0G     0.1248    0.04813          0         43        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00333      0.357    0.00577   0.000897\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       1/49         0G     0.1246    0.04554          0         45        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00319      0.411    0.00334   0.000764\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       2/49         0G     0.1241     0.0476          0         56        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00349      0.393    0.00417   0.000883\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       3/49         0G     0.1187    0.04686          0         39        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00361      0.464    0.00519    0.00125\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       4/49         0G     0.1141    0.04749          0         43        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00658      0.518    0.00816    0.00189\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       5/49         0G     0.1102      0.046          0         39        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00713      0.482      0.016    0.00375\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       6/49         0G     0.1066    0.06123          0         67        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00919      0.589      0.022    0.00467\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       7/49         0G     0.1013    0.06173          0         51        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00866      0.643     0.0214    0.00463\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       8/49         0G    0.09558    0.05501          0         46        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0138      0.589     0.0257    0.00541\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       9/49         0G    0.09407    0.05596          0         47        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0251      0.518     0.0344    0.00794\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      10/49         0G    0.09266     0.0601          0         49        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0173      0.625     0.0393    0.00957\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      11/49         0G    0.09012    0.06977          0         55        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0538      0.482     0.0614     0.0148\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      12/49         0G    0.08621    0.06439          0         49        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0391      0.589     0.0759     0.0206\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      13/49         0G    0.08474    0.06338          0         50        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.126      0.482      0.119      0.032\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      14/49         0G    0.08344    0.07336          0         56        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.167      0.357      0.147     0.0415\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      15/49         0G    0.08671    0.06102          0         47        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.201      0.319      0.174     0.0482\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      16/49         0G    0.07842    0.05551          0         33        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.278      0.429      0.232     0.0709\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      17/49         0G     0.0767    0.05835          0         48        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.277      0.482      0.258     0.0831\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      18/49         0G    0.07896    0.05791          0         49        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.293        0.5      0.302      0.102\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      19/49         0G    0.07672    0.06556          0         52        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.421      0.482      0.379      0.112\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      20/49         0G    0.07541    0.07307          0         61        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.608      0.472      0.537      0.161\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      21/49         0G    0.07175    0.06609          0         59        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.517      0.554      0.567       0.16\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      22/49         0G    0.07598    0.06253          0         55        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.616      0.589      0.605      0.192\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      23/49         0G    0.06909    0.06235          0         57        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.619      0.518      0.639      0.205\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      24/49         0G    0.07158    0.05666          0         44        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.452       0.56      0.442      0.116\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      25/49         0G    0.07012    0.04761          0         48        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.467      0.563      0.434      0.111\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      26/49         0G    0.06818    0.05174          0         51        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0966      0.732     0.0928     0.0263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      27/49         0G    0.07575    0.05413          0         53        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0966      0.732     0.0928     0.0263\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      28/49         0G    0.07064    0.05106          0         48        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.362      0.696      0.327      0.103\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      29/49         0G    0.07087    0.06095          0         70        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.114      0.554      0.109     0.0331\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      30/49         0G    0.07433     0.0491          0         42        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.114      0.554      0.109     0.0331\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      31/49         0G    0.06971    0.06218          0         70        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.442      0.536      0.532      0.191\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      32/49         0G    0.06217    0.05293          0         52        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.338      0.554      0.416      0.131\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      33/49         0G    0.06708    0.04415          0         48        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.338      0.554      0.416      0.131\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      34/49         0G     0.0683    0.05096          0         55        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.441      0.482      0.487      0.187\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      35/49         0G    0.06567    0.04696          0         47        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.435      0.592       0.44      0.189\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      36/49         0G    0.05538    0.04951          0         54        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.435      0.592       0.44      0.189\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      37/49         0G    0.05508    0.04809          0         46        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.444      0.661      0.535      0.242\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      38/49         0G    0.05573    0.04605          0         42        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.531      0.668      0.613      0.298\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      39/49         0G    0.06083    0.04738          0         50        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.531      0.668      0.613      0.298\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      40/49         0G    0.05476    0.04538          0         38        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.591      0.768      0.648      0.303\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      41/49         0G    0.05373    0.05002          0         51        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.526      0.714      0.621      0.256\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      42/49         0G    0.05396    0.03877          0         35        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.526      0.714      0.621      0.256\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      43/49         0G    0.05903    0.04593          0         51        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.677      0.748      0.721      0.349\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      44/49         0G    0.05224    0.04927          0         66        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.677      0.748      0.721      0.349\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      45/49         0G    0.04986    0.04365          0         49        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.749       0.75      0.808      0.364\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      46/49         0G    0.04776    0.04044          0         42        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.749       0.75      0.808      0.364\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      47/49         0G    0.05038    0.04195          0         43        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.774      0.768      0.791      0.439\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      48/49         0G    0.05186     0.0473          0         53        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.774      0.768      0.791      0.439\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      49/49         0G    0.05287    0.03928          0         39        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.814      0.804      0.821      0.463\n",
      "\n",
      "50 epochs completed in 0.580 hours.\n",
      "Optimizer stripped from runs/train/exp24/weights/last.pt, 14.3MB\n",
      "Optimizer stripped from runs/train/exp24/weights/best.pt, 14.3MB\n",
      "\n",
      "Validating runs/train/exp24/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.815      0.804      0.821      0.462\n",
      "Results saved to \u001b[1mruns/train/exp24\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/Users/bhavnasharma/Downloads/SinGAN/yolov5/data_750.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=cpu, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
      "YOLOv5 🚀 v7.0-389-ge62a31b6 Python-3.8.3 torch-1.8.0 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/bhavnasharma/Downloads/SinGAN/yolov5/data/labels/train_75\u001b[0mError decoding JSON from /Users/bhavnasharma/Library/Application Support/Ultralytics/settings.json. Starting with an empty dictionary.\n",
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/Users/bhavnasharma/Library/Application Support/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/bhavnasharma/Downloads/SinGAN/yolov5/data/labels/train_75\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/bhavnasharma/Downloads/SinGAN/yolov5/data/labels/train_750.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/bhavnasharma/Downloads/SinGAN/yolov5/data/labels/val.cache.\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.71 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Plotting labels to runs/train/exp25/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp25\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       0/49         0G     0.1238    0.04737          0         25        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00333      0.411    0.00525   0.000871\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       1/49         0G     0.1245    0.04298          0         21        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00347      0.446    0.00355   0.000778\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       2/49         0G      0.118    0.04658          0         17        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00444      0.571    0.00627    0.00148\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       3/49         0G     0.1109    0.05351          0         26        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56    0.00756      0.625     0.0157    0.00361\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       4/49         0G     0.1029    0.05758          0         24        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0182        0.5     0.0232    0.00484\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       5/49         0G    0.09707    0.04999          0         14        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0229      0.482     0.0238    0.00619\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       6/49         0G    0.09645    0.05307          0         17        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0559      0.321     0.0426     0.0116\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       7/49         0G    0.08986    0.06448          0         25        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0907      0.159     0.0674     0.0185\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       8/49         0G    0.08931    0.05492          0         19        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.162      0.232      0.144     0.0391\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       9/49         0G    0.08184    0.05871          0         23        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.289      0.286      0.235     0.0656\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      10/49         0G    0.07898    0.06653          0         26        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.402      0.518      0.417      0.135\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      11/49         0G    0.07519    0.05558          0         20        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.229      0.411      0.229     0.0712\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      12/49         0G    0.07626    0.05996          0         25        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0402      0.571     0.0425     0.0123\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      13/49         0G    0.07804    0.06082          0         25        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.592      0.679      0.587      0.151\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      14/49         0G    0.07197    0.05018          0         20        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.449      0.567      0.415     0.0987\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      15/49         0G    0.07205    0.04932          0         22        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.105      0.536     0.0925       0.03\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      16/49         0G     0.0689    0.04679          0         26        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.333      0.518      0.361      0.127\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      17/49         0G    0.06433    0.04249          0         24        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.391      0.589      0.455      0.165\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      18/49         0G    0.07063    0.05771          0         35        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.347      0.554      0.434      0.174\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      19/49         0G    0.06486    0.04763          0         25        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56       0.53      0.732      0.601      0.265\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      20/49         0G      0.067    0.03785          0         17        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.452      0.604      0.562      0.218\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      21/49         0G    0.06042    0.04112          0         13        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.656      0.696      0.761      0.333\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      22/49         0G    0.06052    0.03994          0         20        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.556      0.732       0.71      0.308\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      23/49         0G    0.05555    0.04392          0         28        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.585      0.821      0.684      0.283\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      24/49         0G    0.06017    0.03729          0         16        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.488      0.768      0.601      0.229\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      25/49         0G     0.0571    0.04167          0         26        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56       0.58      0.857      0.682      0.233\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      26/49         0G    0.06528    0.03663          0         19        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.705      0.854      0.849      0.449\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      27/49         0G    0.05365    0.04329          0         31        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.406      0.804      0.554      0.229\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      28/49         0G    0.06034    0.03588          0         24        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.406      0.804      0.554      0.229\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      29/49         0G    0.05917    0.04088          0         31        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.526      0.813      0.659      0.275\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      30/49         0G     0.0522    0.03251          0         23        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.537      0.857      0.676      0.369\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      31/49         0G    0.05431    0.03419          0         24        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.576      0.768      0.719      0.357\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      32/49         0G    0.05284    0.03923          0         31        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.576      0.768      0.719      0.357\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      33/49         0G    0.05089    0.03791          0         28        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.605      0.804      0.698      0.357\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      34/49         0G    0.04742    0.03467          0         31        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.596      0.763      0.719      0.379\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      35/49         0G    0.04998    0.03818          0         29        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.654      0.742      0.758       0.47\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      36/49         0G    0.04445     0.0321          0         21        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.654      0.742      0.758       0.47\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      37/49         0G    0.04408    0.03378          0         18        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.809      0.839      0.911      0.582\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      38/49         0G    0.04068    0.03442          0         19        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.541      0.839      0.708      0.393\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      39/49         0G    0.04801    0.03663          0         25        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.706      0.857      0.837      0.473\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      40/49         0G      0.042    0.03326          0         21        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.706      0.857      0.837      0.473\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      41/49         0G    0.04178    0.03157          0         22        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.568      0.964      0.762      0.483\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      42/49         0G    0.03804     0.0317          0         26        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.826      0.964      0.946      0.649\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      43/49         0G    0.03855    0.03101          0         22        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.835      0.964      0.938      0.612\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      44/49         0G    0.03955     0.0333          0         24        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.835      0.964      0.938      0.612\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      45/49         0G    0.03516    0.03115          0         27        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.993      0.964      0.993        0.7\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      46/49         0G    0.03222    0.02888          0         30        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.906      0.964      0.973      0.709\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      47/49         0G    0.03644    0.03276          0         20        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.982      0.972      0.994      0.754\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      48/49         0G    0.03398    0.03148          0         21        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.982      0.972      0.994      0.754\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      49/49         0G    0.03194    0.03332          0         29        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.981      0.982      0.994      0.759\n",
      "\n",
      "50 epochs completed in 0.738 hours.\n",
      "Optimizer stripped from runs/train/exp25/weights/last.pt, 14.3MB\n",
      "Optimizer stripped from runs/train/exp25/weights/best.pt, 14.3MB\n",
      "\n",
      "Validating runs/train/exp25/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.981      0.982      0.994      0.765\n",
      "Results saved to \u001b[1mruns/train/exp25\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 640 --batch 16 --epochs 50 --data /Users/bhavnasharma/Downloads/SinGAN/yolov5/data_500.yaml --weights yolov5s.pt --device cpu\n",
    "!python train.py --img 640 --batch 16 --epochs 50 --data /Users/bhavnasharma/Downloads/SinGAN/yolov5/data_750.yaml --weights yolov5s.pt --device cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/Users/bhavnasharma/Downloads/SinGAN/yolov5/data_100.yaml, weights=['/Users/bhavnasharma/Downloads/SinGAN/yolov5/runs/train/exp21/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
      "YOLOv5 🚀 v7.0-389-ge62a31b6 Python-3.8.3 torch-1.8.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/bhavnasharma/Downloads/SinGAN/yolov5/data/labels/val.cache.\u001b[0m\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56     0.0323      0.321     0.0298    0.00747\n",
      "Speed: 1.2ms pre-process, 145.2ms inference, 48.9ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/exp7\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/Users/bhavnasharma/Downloads/SinGAN/yolov5/data_250.yaml, weights=['/Users/bhavnasharma/Downloads/SinGAN/yolov5/runs/train/exp22/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
      "YOLOv5 🚀 v7.0-389-ge62a31b6 Python-3.8.3 torch-1.8.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/bhavnasharma/Downloads/SinGAN/yolov5/data/labels/val.cache.\u001b[0m\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.238      0.321      0.187     0.0544\n",
      "Speed: 1.4ms pre-process, 137.8ms inference, 29.2ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/exp8\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/Users/bhavnasharma/Downloads/SinGAN/yolov5/data_500.yaml, weights=['/Users/bhavnasharma/Downloads/SinGAN/yolov5/runs/train/exp24/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
      "YOLOv5 🚀 v7.0-389-ge62a31b6 Python-3.8.3 torch-1.8.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/bhavnasharma/Downloads/SinGAN/yolov5/data/labels/val.cache.\u001b[0m\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.815      0.804      0.821      0.463\n",
      "Speed: 1.2ms pre-process, 135.2ms inference, 9.1ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/exp9\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/Users/bhavnasharma/Downloads/SinGAN/yolov5/data_750.yaml, weights=['/Users/bhavnasharma/Downloads/SinGAN/yolov5/runs/train/exp25/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
      "YOLOv5 🚀 v7.0-389-ge62a31b6 Python-3.8.3 torch-1.8.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/bhavnasharma/Downloads/SinGAN/yolov5/data/labels/val.cache.\u001b[0m\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.981      0.982      0.994      0.765\n",
      "Speed: 1.2ms pre-process, 138.4ms inference, 1.4ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/exp10\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/Users/bhavnasharma/Downloads/SinGAN/yolov5/data.yaml, weights=['/Users/bhavnasharma/Downloads/SinGAN/yolov5/runs/train/exp3/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
      "YOLOv5 🚀 v7.0-389-ge62a31b6 Python-3.8.3 torch-1.8.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/bhavnasharma/Downloads/SinGAN/yolov5/data/labels/val.cache.\u001b[0m\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         24         56      0.982      0.952      0.991      0.726\n",
      "Speed: 1.7ms pre-process, 141.7ms inference, 1.5ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/exp11\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Validate the model for each dataset size and capture the output\n",
    "!python val.py --weights /Users/bhavnasharma/Downloads/SinGAN/yolov5/runs/train/exp21/weights/best.pt --data /Users/bhavnasharma/Downloads/SinGAN/yolov5/data_100.yaml > results_100.txt\n",
    "!python val.py --weights /Users/bhavnasharma/Downloads/SinGAN/yolov5/runs/train/exp22/weights/best.pt --data /Users/bhavnasharma/Downloads/SinGAN/yolov5/data_250.yaml > results_250.txt\n",
    "!python val.py --weights /Users/bhavnasharma/Downloads/SinGAN/yolov5/runs/train/exp24/weights/best.pt --data /Users/bhavnasharma/Downloads/SinGAN/yolov5/data_500.yaml > results_500.txt\n",
    "!python val.py --weights /Users/bhavnasharma/Downloads/SinGAN/yolov5/runs/train/exp25/weights/best.pt --data /Users/bhavnasharma/Downloads/SinGAN/yolov5/data_750.yaml > results_750.txt\n",
    "!python val.py --weights /Users/bhavnasharma/Downloads/SinGAN/yolov5/runs/train/exp3/weights/best.pt --data /Users/bhavnasharma/Downloads/SinGAN/yolov5/data.yaml > results_1000.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset_sizes = [100, 250, 500, 750, 1000]\n",
    "\n",
    "precision_list, recall_list, map50_list = [0.0323, 0.238, 0.815, 0.981, 0.982], [0.321,0.321, 0.804, 0.982, 0.952], [0.0298, 0.187, 0.821, 0.994, 0.991]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(dataset_sizes, precision_list, label='Precision', marker='o')\n",
    "plt.plot(dataset_sizes, recall_list, label='Recall', marker='o')\n",
    "plt.plot(dataset_sizes, map50_list, label='mAP50', marker='o')\n",
    "plt.xlabel('Number of Training Images')\n",
    "plt.ylabel('Metrics')\n",
    "plt.title('Model Performance vs. Number of Training Images')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/Users/bhavnasharma/Downloads/SinGAN/yolov5/hold.yaml, weights=['/Users/bhavnasharma/Downloads/SinGAN/yolov5/runs/train/exp3/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
      "YOLOv5 🚀 v7.0-389-ge62a31b6 Python-3.8.3 torch-1.8.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/bhavnasharma/Downloads/SinGAN/yolov5/data/holdout.cache... \u001b[0m\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          1          2          0          0          0          0\n",
      "Speed: 1.2ms pre-process, 148.3ms inference, 2.5ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/exp15\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python val.py --weights /Users/bhavnasharma/Downloads/SinGAN/yolov5/runs/train/exp3/weights/best.pt --data /Users/bhavnasharma/Downloads/SinGAN/yolov5/hold.yaml \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test Fater R-CNN performance on dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bhavnasharma/Downloads/SinGAN\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/bhavnasharma/Downloads/SinGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied 50 images and 50 labels to /Users/bhavnasharma/Downloads/SinGAN/Faster-R-CNN-2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "source_images = \"/Users/bhavnasharma/Downloads/SinGAN/Results/images\"\n",
    "source_labels = \"/Users/bhavnasharma/Downloads/SinGAN/Results/labels\"\n",
    "destination = \"/Users/bhavnasharma/Downloads/SinGAN/Faster-R-CNN-2\"\n",
    "\n",
    "# Create destination folders\n",
    "dest_images = os.path.join(destination, \"images\")\n",
    "dest_labels = os.path.join(destination, \"labels\")\n",
    "\n",
    "os.makedirs(dest_images, exist_ok=True)\n",
    "os.makedirs(dest_labels, exist_ok=True)\n",
    "\n",
    "# Copy images and labels\n",
    "for file_name in os.listdir(source_images):\n",
    "    shutil.copy(os.path.join(source_images, file_name), os.path.join(dest_images, file_name))\n",
    "\n",
    "for file_name in os.listdir(source_labels):\n",
    "    shutil.copy(os.path.join(source_labels, file_name), os.path.join(dest_labels, file_name))\n",
    "\n",
    "print(f\"Copied {len(os.listdir(dest_images))} images and {len(os.listdir(dest_labels))} labels to {destination}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved COCO annotations to /Users/bhavnasharma/Downloads/SinGAN/Faster-R-CNN-2/dataset_coco.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import cv2\n",
    "\n",
    "# Define paths\n",
    "image_dir = \"/Users/bhavnasharma/Downloads/SinGAN/Faster-R-CNN-2/images\"\n",
    "label_dir = \"/Users/bhavnasharma/Downloads/SinGAN/Faster-R-CNN-2/labels\"\n",
    "output_json = \"/Users/bhavnasharma/Downloads/SinGAN/Faster-R-CNN-2/dataset_coco.json\"\n",
    "\n",
    "# Function to convert YOLO annotations to COCO format\n",
    "def convert_yolo_to_coco(image_dir, label_dir, output_json):\n",
    "    images, annotations = [], []\n",
    "    categories = [{\"id\": 1, \"name\": \"pedestrian\"}]  # Adjust categories if needed\n",
    "    annotation_id = 0\n",
    "\n",
    "    for idx, image_file in enumerate(os.listdir(image_dir)):\n",
    "        if not image_file.endswith(\".png\"):\n",
    "            continue\n",
    "        \n",
    "        image_path = os.path.join(image_dir, image_file)\n",
    "        label_path = os.path.join(label_dir, image_file.replace(\".png\", \".txt\"))\n",
    "\n",
    "        # Get image dimensions\n",
    "        img = cv2.imread(image_path)\n",
    "        height, width, _ = img.shape\n",
    "\n",
    "        # Add image metadata\n",
    "        images.append({\"file_name\": image_file, \"width\": width, \"height\": height, \"id\": idx})\n",
    "\n",
    "        # Read YOLO label file\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            for line in lines:\n",
    "                class_id, x_center, y_center, box_w, box_h = map(float, line.strip().split())\n",
    "\n",
    "                # Convert YOLO format to absolute COCO format\n",
    "                abs_x = int((x_center - box_w / 2) * width)\n",
    "                abs_y = int((y_center - box_h / 2) * height)\n",
    "                abs_width = int(box_w * width)\n",
    "                abs_height = int(box_h * height)\n",
    "                \n",
    "                abs_xmax = abs_x + abs_width\n",
    "                abs_ymax = abs_y + abs_height\n",
    "\n",
    "                # Ensure bounding box does not exceed image dimensions\n",
    "                abs_x = max(0, min(abs_x, width - 1))\n",
    "                abs_y = max(0, min(abs_y, height - 1))\n",
    "                abs_xmax = min(abs_xmax, width)\n",
    "                abs_ymax = min(abs_ymax, height)\n",
    "\n",
    "                annotations.append({\n",
    "                    \"image_id\": idx,\n",
    "                    \"category_id\": int(class_id + 1),  # Adjust class ID if needed\n",
    "                    \"bbox\": [abs_x, abs_y, abs_xmax, abs_ymax],\n",
    "                    \"area\": abs_width * abs_height,\n",
    "                    \"iscrowd\": 0,\n",
    "                    \"id\": annotation_id\n",
    "                })\n",
    "                annotation_id += 1\n",
    "\n",
    "    # Save to COCO JSON file\n",
    "    coco_format = {\"images\": images, \"annotations\": annotations, \"categories\": categories}\n",
    "\n",
    "    with open(output_json, \"w\") as f:\n",
    "        json.dump(coco_format, f, indent=4)\n",
    "\n",
    "    print(f\"Saved COCO annotations to {output_json}\")\n",
    "\n",
    "convert_yolo_to_coco(image_dir, label_dir, output_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Splitting done: Generated datasets for all training percentages.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.ops import box_iou\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# Load full dataset\n",
    "img_dir = \"/Users/bhavnasharma/Downloads/SinGAN/Faster-R-CNN-2/images\"\n",
    "ann_file = \"/Users/bhavnasharma/Downloads/SinGAN/Faster-R-CNN-2/dataset_coco.json\"\n",
    "full_dataset = CocoDetection(root=img_dir, annFile=ann_file, transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "# Split percentages\n",
    "split_percentages = [0.02, 0.2, 0.4, 0.6, 0.8]  # First 1 image, then % of dataset\n",
    "num_images = len(full_dataset)\n",
    "\n",
    "# Generate training/testing splits\n",
    "split_results = []\n",
    "for split in split_percentages:\n",
    "    train_size = max(1, int(num_images * split))  # Ensure at least 1 image for training\n",
    "    indices = list(range(num_images))\n",
    "    random.shuffle(indices)\n",
    "\n",
    "    train_indices = indices[:train_size]\n",
    "    test_indices = indices[train_size:]\n",
    "\n",
    "    train_subset = Subset(full_dataset, train_indices)\n",
    "    test_subset = Subset(full_dataset, test_indices)\n",
    "\n",
    "    split_results.append((train_subset, test_subset))\n",
    "\n",
    "print(\"Splitting done: Generated datasets for all training percentages.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import defaultdict\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images, targets = zip(*batch)\n",
    "    formatted_images, formatted_targets = [], []\n",
    "\n",
    "    image_annotations = defaultdict(list)\n",
    "    for anns in targets:\n",
    "        for ann in anns:\n",
    "            image_annotations[ann[\"image_id\"]].append(ann)\n",
    "\n",
    "    for img, anns in zip(images, targets):\n",
    "        if anns:\n",
    "            image_id = anns[0][\"image_id\"]\n",
    "            matched_annotations = image_annotations[image_id]\n",
    "\n",
    "            if matched_annotations:\n",
    "                valid_boxes = torch.tensor([ann[\"bbox\"] for ann in matched_annotations], dtype=torch.float32)\n",
    "                valid_labels = torch.tensor([ann[\"category_id\"] for ann in matched_annotations], dtype=torch.int64)\n",
    "\n",
    "                formatted_target = {\n",
    "                    \"boxes\": valid_boxes,\n",
    "                    \"labels\": valid_labels\n",
    "                }\n",
    "                formatted_images.append(img)\n",
    "                formatted_targets.append(formatted_target)\n",
    "\n",
    "    return formatted_images, formatted_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_subset, test_subset):\n",
    "    train_loader = DataLoader(train_subset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_subset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    model.train()\n",
    "\n",
    "    num_epochs = 10\n",
    "    loss_values = []  # Track loss per epoch\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for images, targets in train_loader:\n",
    "            images = [image.to(device) for image in images]\n",
    "\n",
    "            if len(targets) == 0:\n",
    "                continue\n",
    "\n",
    "            formatted_targets = [{\"boxes\": t[\"boxes\"].to(device), \"labels\": t[\"labels\"].to(device)} for t in targets]\n",
    "            loss_dict = model(images, formatted_targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += losses.item()\n",
    "\n",
    "        loss_values.append(total_loss)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "    # Evaluate model\n",
    "    model.eval()\n",
    "    all_precisions, all_recalls, all_f1s = [], [], []\n",
    "\n",
    "    for i, (image, target) in enumerate(test_loader):\n",
    "        if not image or len(image) == 0:  # Prevent empty batch errors\n",
    "            print(f\"⚠ Skipping test image {i} due to empty batch\")\n",
    "            continue\n",
    "        \n",
    "        image_tensor = image[0].to(device)\n",
    "        \n",
    "        with torch.no_grad():  # No gradients for inference\n",
    "            output = model([image_tensor])\n",
    "\n",
    "        pred_boxes = output[0][\"boxes\"].cpu()\n",
    "        pred_labels = output[0][\"labels\"].cpu()\n",
    "        pred_scores = output[0][\"scores\"].cpu()\n",
    "\n",
    "        gt_boxes = target[0][\"boxes\"]\n",
    "        gt_labels = target[0][\"labels\"]\n",
    "        \n",
    "        # Ensure predictions and ground-truth boxes exist before computing IoU\n",
    "        if gt_boxes.numel() == 0 or pred_boxes.numel() == 0:\n",
    "            print(f\"⚠ Skipping IoU calculation for image {i} (No objects detected)\")\n",
    "            continue  \n",
    "\n",
    "\n",
    "        iou_matrix = box_iou(gt_boxes, pred_boxes)\n",
    "        max_iou, _ = iou_matrix.max(dim=1)\n",
    "\n",
    "        tp = sum(iou > 0.5 for iou in max_iou)\n",
    "        fp = len(pred_boxes) - tp\n",
    "        fn = len(gt_boxes) - tp\n",
    "\n",
    "        precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "        recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "\n",
    "        all_precisions.append(precision)\n",
    "        all_recalls.append(recall)\n",
    "        all_f1s.append(f1_score)\n",
    "\n",
    "    avg_precision = sum(all_precisions) / len(all_precisions)\n",
    "    avg_recall = sum(all_recalls) / len(all_recalls)\n",
    "    avg_f1 = sum(all_f1s) / len(all_f1s)\n",
    "\n",
    "    return loss_values, avg_precision, avg_recall, avg_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 2% of dataset...\n",
      "Epoch 1/10, Loss: 1.0624\n",
      "Epoch 2/10, Loss: 0.5663\n",
      "Epoch 3/10, Loss: 0.4619\n",
      "Epoch 4/10, Loss: 0.3468\n",
      "Epoch 5/10, Loss: 0.3246\n",
      "Epoch 6/10, Loss: 0.2784\n",
      "Epoch 7/10, Loss: 0.2554\n",
      "Epoch 8/10, Loss: 0.1869\n",
      "Epoch 9/10, Loss: 0.1838\n",
      "Epoch 10/10, Loss: 0.1773\n",
      "⚠ Skipping test image 17 due to empty batch\n",
      "⚠ Skipping test image 30 due to empty batch\n",
      "⚠ Skipping IoU calculation for image 38 (No objects detected)\n",
      "⚠ Skipping IoU calculation for image 48 (No objects detected)\n",
      "Training with 20% of dataset...\n",
      "Epoch 1/10, Loss: 1.6179\n",
      "Epoch 2/10, Loss: 1.0379\n",
      "Epoch 3/10, Loss: 0.7646\n",
      "Epoch 4/10, Loss: 0.6357\n",
      "Epoch 5/10, Loss: 0.4142\n",
      "Epoch 6/10, Loss: 0.3197\n",
      "Epoch 7/10, Loss: 0.4032\n",
      "Epoch 8/10, Loss: 0.3063\n",
      "Epoch 9/10, Loss: 0.3777\n",
      "Epoch 10/10, Loss: 0.3372\n",
      "⚠ Skipping test image 1 due to empty batch\n",
      "⚠ Skipping test image 38 due to empty batch\n",
      "Training with 40% of dataset...\n",
      "Epoch 1/10, Loss: 1.5709\n",
      "Epoch 2/10, Loss: 0.8324\n",
      "Epoch 3/10, Loss: 0.5991\n",
      "Epoch 4/10, Loss: 0.4759\n",
      "Epoch 5/10, Loss: 0.3480\n",
      "Epoch 6/10, Loss: 0.2884\n",
      "Epoch 7/10, Loss: 0.2962\n",
      "Epoch 8/10, Loss: 0.2546\n",
      "Epoch 9/10, Loss: 0.2146\n",
      "Epoch 10/10, Loss: 0.2028\n",
      "Training with 60% of dataset...\n",
      "Epoch 1/10, Loss: 1.1714\n",
      "Epoch 2/10, Loss: 0.7088\n",
      "Epoch 3/10, Loss: 0.5836\n",
      "Epoch 4/10, Loss: 0.4745\n",
      "Epoch 5/10, Loss: 0.3566\n",
      "Epoch 6/10, Loss: 0.3537\n",
      "Epoch 7/10, Loss: 0.3155\n",
      "Epoch 8/10, Loss: 0.2867\n",
      "Epoch 9/10, Loss: 0.2771\n",
      "Epoch 10/10, Loss: 0.2335\n",
      "⚠ Skipping test image 17 due to empty batch\n",
      "Training with 80% of dataset...\n",
      "Epoch 1/10, Loss: 0.8897\n",
      "Epoch 2/10, Loss: 0.6247\n",
      "Epoch 3/10, Loss: 0.5081\n",
      "Epoch 4/10, Loss: 0.4432\n",
      "Epoch 5/10, Loss: 0.3212\n",
      "Epoch 6/10, Loss: 0.3162\n",
      "Epoch 7/10, Loss: 0.2774\n",
      "Epoch 8/10, Loss: 0.2713\n",
      "Epoch 9/10, Loss: 0.2713\n",
      "Epoch 10/10, Loss: 0.2672\n",
      "Completed: Collected Precision, Recall, F1-score, and Loss values.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Faster R-CNN model\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "num_classes = 2  # 1 object class + background\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# Run training on different splits\n",
    "precision_vals, recall_vals, f1_vals, loss_vals = [], [], [], []\n",
    "train_sizes = [2, 20, 40, 60, 80]  # Training dataset sizes in %\n",
    "\n",
    "for i, (train_subset, test_subset) in enumerate(split_results):\n",
    "    print(f\"Training with {train_sizes[i]}% of dataset...\")\n",
    "\n",
    "    loss_values, precision, recall, f1 = train_and_evaluate(model, train_subset, test_subset)\n",
    "    precision_vals.append(precision)\n",
    "    recall_vals.append(recall)\n",
    "    f1_vals.append(f1)\n",
    "    loss_vals.append(loss_values)\n",
    "\n",
    "print(\"Completed: Collected Precision, Recall, F1-score, and Loss values.\")\n",
    "\n",
    "# Plot Loss Curve\n",
    "plt.figure(figsize=(8, 5))\n",
    "for i, losses in enumerate(loss_vals):\n",
    "    plt.plot(range(1, 11), losses, label=f\"{train_sizes[i]}% data\")\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.title(\"Loss Trend Across Dataset Sizes\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot Performance Metrics\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_sizes, precision_vals, label=\"Precision\", marker=\"o\", linestyle=\"-\")\n",
    "plt.plot(train_sizes, recall_vals, label=\"Recall\", marker=\"s\", linestyle=\"-\")\n",
    "plt.plot(train_sizes, f1_vals, label=\"F1 Score\", marker=\"d\", linestyle=\"-\")\n",
    "\n",
    "plt.xlabel(\"Training Data Percentage\")\n",
    "plt.ylabel(\"Performance Metrics\")\n",
    "plt.title(\"Model Performance with Increasing Training Data\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
